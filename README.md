# Tumor-Tracer
Un trazador de IA multi-etapa: Clasifica la imagen (SVM), Dibuja el contorno (U-Net) y Perfecciona el trazo (RL).

## ğŸ¯ DescripciÃ³n del Proyecto

**Tumor-Tracer** es un sistema asistente de segmentaciÃ³n de imÃ¡genes mÃ©dicas diseÃ±ado para abordar un problema crÃ­tico en HealthTech: **acelerar el diagnÃ³stico y la planificaciÃ³n del tratamiento mediante el anÃ¡lisis automatizado de imÃ¡genes de resonancia magnÃ©tica (MRI) cerebrales**.

### Valor Empresarial

- **ReducciÃ³n de Horas de Trabajo**: Disminuye significativamente el tiempo que radiÃ³logos y cirujanos dedican al anÃ¡lisis manual de imÃ¡genes
- **Mediciones Objetivas**: Proporciona mediciones cuantitativas y objetivas del tamaÃ±o y localizaciÃ³n de tumores cerebrales
- **Prototipo SaMD**: Desarrolla un prototipo de Software as a Medical Device (SaMD) para aplicaciones clÃ­nicas

### Dataset: LGG MRI Segmentation

Este proyecto utiliza el dataset **LGG MRI Segmentation**, ideal por las siguientes razones:

- **TamaÃ±o Manejable**: 88MB con 2,150 archivos de imÃ¡genes
- **Ciclos de Entrenamiento RÃ¡pidos**: Permite iteraciones rÃ¡pidas (horas, no dÃ­as)
- **Tarea Clara**: SegmentaciÃ³n semÃ¡ntica de tumores cerebrales de bajo grado (Low-Grade Glioma)
- **Anotaciones Completas**: Incluye imÃ¡genes MRI y mÃ¡scaras de segmentaciÃ³n (ground truth)

## ğŸ—ï¸ Arquitectura Multi-Etapa

El proyecto estÃ¡ diseÃ±ado en **tres fases evolutivas**, cada una construyendo sobre la anterior, demostrando la progresiÃ³n desde ML clÃ¡sico hasta tÃ©cnicas avanzadas de RL:

### ğŸ“Š Fase 1: Clasificador de Imagen Completa (ML ClÃ¡sico)

**Objetivo de Negocio**: Crear un modelo baseline rÃ¡pido para una primera criba: Â¿contiene esta imagen MRI algÃºn tumor o no?

**Tarea de ML**: ClasificaciÃ³n de ImÃ¡genes (Binaria)

**MetodologÃ­a**:
- **IngenierÃ­a de CaracterÃ­sticas**:
  - CaracterÃ­sticas de textura GLCM (Gray-Level Co-occurrence Matrix)
  - EstadÃ­sticas de histograma de intensidad
  - Descriptores de forma
- **Modelo**: Support Vector Machine (SVM)
- **Output**: PredicciÃ³n binaria (0 = sin tumor, 1 = con tumor)

**Resultado**: Un modelo que puede marcar rÃ¡pidamente imÃ¡genes para revisiÃ³n, pero no puede indicar dÃ³nde estÃ¡ el tumor.

**LimitaciÃ³n**: No proporciona localizaciÃ³n espacial del tumor.

---

### ğŸ¨ Fase 2: Segmentador de PrecisiÃ³n (Deep Learning)

**Objetivo de Negocio**: Proporcionar una herramienta de diagnÃ³stico precisa que delinee el contorno exacto del tumor para la planificaciÃ³n quirÃºrgica.

**Tarea de DL**: SegmentaciÃ³n SemÃ¡ntica

**MetodologÃ­a**:
- **Arquitectura**: U-Net, el estÃ¡ndar de oro en segmentaciÃ³n de imÃ¡genes biomÃ©dicas
  - Arquitectura encoder-decoder con skip connections
  - Captura contexto global y detalles locales simultÃ¡neamente
- **Entrenamiento**: Dada una imagen MRI, el modelo genera la mÃ¡scara de segmentaciÃ³n correspondiente
- **MÃ©tricas**: Dice Score, Intersection over Union (IoU)

**Resultado**: Un modelo de DL que produce mapas de segmentaciÃ³n precisos, delineando pÃ­xel por pÃ­xel el contorno del tumor.

**Avance**: TransiciÃ³n de clasificaciÃ³n binaria a localizaciÃ³n espacial precisa.

---

### ğŸ¤– Fase 3: Agente de AnotaciÃ³n Interactiva (Reinforcement Learning)

**Objetivo de Negocio**: Reducir drÃ¡sticamente el tiempo de anotaciÃ³n humana creando un "copiloto" de IA que aprende a corregir errores con la mÃ­nima intervenciÃ³n.

**Tarea de RL**: OptimizaciÃ³n de PolÃ­ticas (Active Learning / Interactive Segmentation)

**MetodologÃ­a (SimulaciÃ³n)**:

**Componentes del MDP (Markov Decision Process)**:

1. **Estado (State)**:
   - Imagen MRI original
   - MÃ¡scara de predicciÃ³n (imperfecta) de la Fase 2
   - Historial de correcciones previas

2. **AcciÃ³n (Action)**:
   - Acciones de ediciÃ³n: "expandir mÃ¡scara en el pÃ­xel (x,y)"
   - Acciones de consulta: "preguntar al humano por la etiqueta en el pÃ­xel (x,y)"
   - Acciones de refinamiento: ajustes locales de la segmentaciÃ³n

3. **Recompensa (Reward)**:
   - Mejora en Dice Score o IoU despuÃ©s de cada acciÃ³n
   - PenalizaciÃ³n por consultas innecesarias al humano
   - Recompensa por convergencia rÃ¡pida a mÃ¡scara correcta

4. **Algoritmo**: Deep Q-Network (DQN)
   - Red neuronal que aprende la funciÃ³n Q(s,a)
   - Explora estrategias Ã³ptimas de refinamiento
   - Aprende cuÃ¡ndo pedir ayuda humana vs. corregir automÃ¡ticamente

**Resultado**: Un prototipo de sistema de anotaciÃ³n asistida por IA que aprende activamente, demostrando cÃ³mo humanos y IA colaboran en tareas de alto riesgo.

**InnovaciÃ³n**: El agente aprende la polÃ­tica Ã³ptima de interacciÃ³n humano-IA para maximizar calidad minimizando esfuerzo humano.

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- Python 3.8+
- CUDA (opcional, para entrenamiento acelerado con GPU)

### InstalaciÃ³n

```bash
# Clonar el repositorio
git clone https://github.com/GabrielJuan349/Tumor-Tracer.git
cd Tumor-Tracer

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

**Fase 1 (ML ClÃ¡sico)**:
- scikit-learn
- scikit-image
- numpy
- pandas
- opencv-python

**Fase 2 (Deep Learning)**:
- tensorflow / pytorch
- keras / torch
- albumentations (data augmentation)
- segmentation-models-pytorch

**Fase 3 (Reinforcement Learning)**:
- gym / gymnasium
- stable-baselines3
- torch

**Utilidades**:
- matplotlib
- seaborn
- tqdm
- pillow

## ğŸ“ Estructura del Proyecto

```
Tumor-Tracer/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Dataset LGG MRI original
â”‚   â”œâ”€â”€ processed/           # Datos preprocesados
â”‚   â””â”€â”€ augmented/           # Datos aumentados
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ phase1_svm/
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â”œâ”€â”€ train_svm.py
â”‚   â”‚   â””â”€â”€ predict_svm.py
â”‚   â”œâ”€â”€ phase2_unet/
â”‚   â”‚   â”œâ”€â”€ unet_model.py
â”‚   â”‚   â”œâ”€â”€ train_unet.py
â”‚   â”‚   â””â”€â”€ predict_unet.py
â”‚   â”œâ”€â”€ phase3_rl/
â”‚   â”‚   â”œâ”€â”€ environment.py
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py
â”‚   â”‚   â”œâ”€â”€ train_dqn.py
â”‚   â”‚   â””â”€â”€ interactive_refine.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py
â”‚       â”œâ”€â”€ preprocessing.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ visualization.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploratory_data_analysis.ipynb
â”‚   â”œâ”€â”€ 02_phase1_svm_experiments.ipynb
â”‚   â”œâ”€â”€ 03_phase2_unet_training.ipynb
â”‚   â””â”€â”€ 04_phase3_rl_training.ipynb
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ svm_classifier.pkl
â”‚   â”œâ”€â”€ unet_segmentation.pth
â”‚   â””â”€â”€ dqn_agent.pth
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ phase1_metrics/
â”‚   â”œâ”€â”€ phase2_segmentations/
â”‚   â””â”€â”€ phase3_refinements/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_phase1.py
â”‚   â”œâ”€â”€ test_phase2.py
â”‚   â””â”€â”€ test_phase3.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

## ğŸ’» Uso

### Fase 1: ClasificaciÃ³n con SVM

```bash
# Entrenar clasificador SVM
python src/phase1_svm/train_svm.py --data data/processed --output models/

# PredicciÃ³n
python src/phase1_svm/predict_svm.py --model models/svm_classifier.pkl --image path/to/mri.png
```

### Fase 2: SegmentaciÃ³n con U-Net

```bash
# Entrenar U-Net
python src/phase2_unet/train_unet.py --data data/processed --epochs 100 --batch-size 8

# SegmentaciÃ³n
python src/phase2_unet/predict_unet.py --model models/unet_segmentation.pth --image path/to/mri.png
```

### Fase 3: Refinamiento con RL

```bash
# Entrenar agente DQN
python src/phase3_rl/train_dqn.py --episodes 1000 --unet-model models/unet_segmentation.pth

# Refinamiento interactivo
python src/phase3_rl/interactive_refine.py --agent models/dqn_agent.pth --image path/to/mri.png
```

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

### Fase 1 (ClasificaciÃ³n)
- **Accuracy**: PrecisiÃ³n general del clasificador
- **Precision/Recall**: Para clase positiva (tumor presente)
- **F1-Score**: Balance entre precisiÃ³n y recall
- **ROC-AUC**: Ãrea bajo la curva ROC

### Fase 2 (SegmentaciÃ³n)
- **Dice Score**: Coeficiente de similitud (principal mÃ©trica)
- **IoU (Jaccard Index)**: Intersection over Union
- **Hausdorff Distance**: Distancia mÃ¡xima entre contornos
- **Pixel Accuracy**: PrecisiÃ³n a nivel de pÃ­xel

### Fase 3 (RL)
- **Dice Improvement**: Mejora en Dice Score tras refinamiento
- **Human Queries**: NÃºmero de consultas al humano
- **Convergence Steps**: Pasos hasta segmentaciÃ³n Ã³ptima
- **Reward per Episode**: Recompensa acumulada

## ğŸ”¬ Resultados Esperados

### Fase 1
- **Baseline rÃ¡pido**: ClasificaciÃ³n en < 100ms por imagen
- **Accuracy objetivo**: > 90% en detecciÃ³n de presencia de tumor

### Fase 2
- **SegmentaciÃ³n precisa**: Dice Score > 0.85
- **Tiempo de inferencia**: < 2 segundos por imagen
- **Calidad clÃ­nica**: Contornos utilizables para planificaciÃ³n quirÃºrgica

### Fase 3
- **Eficiencia de anotaciÃ³n**: ReducciÃ³n del 70% en tiempo de anotaciÃ³n humana
- **Mejora de segmentaciÃ³n**: +5-10% en Dice Score sobre predicciÃ³n inicial
- **InteracciÃ³n inteligente**: < 10 clics humanos para correcciÃ³n completa

## ğŸ› ï¸ Desarrollo y ContribuciÃ³n

### Flujo de Trabajo de Desarrollo

1. **Fork** del repositorio
2. Crear una **rama de feature** (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** de cambios (`git commit -m 'AÃ±ade nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abrir un **Pull Request**

### EstÃ¡ndares de CÃ³digo

- Seguir PEP 8 para cÃ³digo Python
- Documentar funciones con docstrings
- Incluir tests unitarios para nuevas funcionalidades
- Mantener cobertura de tests > 80%

## ğŸ“š Referencias y Recursos

### Papers Fundamentales

**Fase 2 - U-Net**:
- Ronneberger, O., Fischer, P., & Brox, T. (2015). "U-Net: Convolutional Networks for Biomedical Image Segmentation"

**Fase 3 - RL para SegmentaciÃ³n**:
- Luo, X., et al. (2021). "Deep Reinforcement Learning for Interactive Medical Image Segmentation"

### Dataset
- **LGG MRI Segmentation Dataset**: Disponible en Kaggle
- Link: https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation

### Herramientas y Frameworks
- [TensorFlow](https://www.tensorflow.org/)
- [PyTorch](https://pytorch.org/)
- [Scikit-learn](https://scikit-learn.org/)
- [Stable-Baselines3](https://stable-baselines3.readthedocs.io/)

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¥ Autores y Reconocimientos

- **Equipo Tumor-Tracer**: Desarrollo del sistema multi-etapa
- **Kaggle Community**: Por el dataset LGG MRI Segmentation
- **Comunidad Open Source**: Por las herramientas y frameworks utilizados

## ğŸ“§ Contacto

Para preguntas, sugerencias o colaboraciones, por favor:
- Abrir un **Issue** en GitHub
- Contactar al equipo de desarrollo

---

**âš ï¸ Aviso Legal**: Este es un proyecto de investigaciÃ³n y educativo. No debe utilizarse para diagnÃ³stico clÃ­nico real sin la debida validaciÃ³n, certificaciÃ³n mÃ©dica y aprobaciÃ³n regulatoria.
