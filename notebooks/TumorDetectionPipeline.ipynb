{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script de Detecci√≥n de Tumores Cerebrales (Random Forest)\n",
    "=========================================================\n",
    "Este script implementa un pipeline completo de Machine Learning para segmentaci√≥n de tumores.\n",
    "Incluye:\n",
    "1.  Preprocesamiento Avanzado (CLAHE, Denoise, Alineaci√≥n PCA).\n",
    "2.  Ingenier√≠a de Caracter√≠sticas (Color, Textura, Espacial, Simetr√≠a, Interacci√≥n).\n",
    "3.  Entrenamiento eficiente con Subsampling.\n",
    "4.  Validaci√≥n Cruzada y Evaluaci√≥n detallada.\n",
    "\n",
    "Autor: [Tu Nombre/Equipo]\n",
    "Fecha: Diciembre 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "import shutil\n",
    "import traceback\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as nd\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Configurar backend no interactivo para estabilidad en Windows\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURACI√ìN Y CONSTANTES\n",
    "# ==========================================\n",
    "RANDOM_STATE = 42\n",
    "RF_ESTIMATORS = 100\n",
    "RF_MAX_DEPTH = 30\n",
    "RF_CLASS_WEIGHT = {0: 1, 1: 1.5} # Peso 1.5 a Tumor para priorizar sensibilidad sin disparar FPs\n",
    "SUBSAMPLE_RATIO = 3  # Ratio 1 pixel tumor : 3 pixeles fondo\n",
    "CV_FOLDS = 7\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(BASE_DIR) if \"notebooks\" in BASE_DIR else BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. FUNCIONES DE LECTURA E I/O\n",
    "# ==========================================\n",
    "def cv2_imread_unicode(path, flag=cv2.IMREAD_COLOR):\n",
    "    \"\"\"Lee im√°genes soportando caracteres unicode en la ruta (Windows).\"\"\"\n",
    "    try:\n",
    "        stream = np.fromfile(path, dtype=np.uint8)\n",
    "        img = cv2.imdecode(stream, flag)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def limpiar_directorio_resultados(path):\n",
    "    \"\"\"Elimina y recrea el directorio de resultados para una ejecuci√≥n limpia.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    \n",
    "    subdirs = [\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "    for cat in subdirs:\n",
    "        os.makedirs(os.path.join(path, cat), exist_ok=True)\n",
    "    \n",
    "    # Subcarpetas TP por calidad (Deciles) se crean din√°micamente luego\n",
    "    print(f\"Directorio de resultados preparado: {path}\")\n",
    "\n",
    "def log_experiment_to_md(params, metrics, timings, cv_full, feat_imps, filename=\"experiment_history.md\"):\n",
    "    \"\"\"Guarda los resultados del experimento en un archivo Markdown persistente.\"\"\"\n",
    "    path = os.path.join(PROJECT_ROOT, filename)\n",
    "    mode = 'a' if os.path.exists(path) else 'w'\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    with open(path, mode, encoding='utf-8') as f:\n",
    "        if mode == 'w':\n",
    "            f.write(\"# Historial de Experimentos - Tumor Tracer AI\\n\\n\")\n",
    "        \n",
    "        f.write(f\"## üß™ Prueba: {timestamp}\\n\")\n",
    "        f.write(f\"### 1. Configuraci√≥n del Experimento\\n\")\n",
    "        f.write(f\"- **Dataset:** {params['n_images']} im√°genes (Train: {params['n_train']}, Test: {params['n_test']})\\n\")\n",
    "        f.write(f\"- **Random Forest:** `Estimators={params['rf_est']}`, `Depth={params['rf_depth']}`, `ClassWeight={params['rf_weight']}`\\n\")\n",
    "        f.write(f\"- **Tiempos:** Extrac={timings['extraction']:.1f}s | CV={timings['cv']:.1f}s | Train={timings['train']:.1f}s | Inf={timings['inference']:.1f}s | **Total={timings['total']:.1f}s**\\n\")\n",
    "        \n",
    "        f.write(f\"\\n### 2. Validaci√≥n Cruzada (K={CV_FOLDS}) - Estabilidad\\n\")\n",
    "        f.write(f\"| Fold | F1-Score | Precision | Recall |\\n\")\n",
    "        f.write(f\"|------|----------|-----------|--------|\\n\")\n",
    "        for i in range(CV_FOLDS):\n",
    "            f.write(f\"| {i+1} | {cv_full['test_f1'][i]:.4f} | {cv_full['test_precision'][i]:.4f} | {cv_full['test_recall'][i]:.4f} |\\n\")\n",
    "        \n",
    "        f.write(f\"| **Promedio** | **{metrics['cv_f1_mean']:.4f}** ¬± {metrics['cv_f1_std']*2:.4f} | {metrics['cv_prec_mean']:.4f} | {metrics['cv_rec_mean']:.4f} |\\n\")\n",
    "        \n",
    "        f.write(f\"\\n### 3. Importancia de Caracter√≠sticas (Top Influencias)\\n\")\n",
    "        f.write(f\"| Ranking | Caracter√≠stica | Importancia | Descripci√≥n |\\n\")\n",
    "        f.write(f\"|:-------:|----------------|-------------|-------------|\\n\")\n",
    "        \n",
    "        # Diccionario de descripciones breves\n",
    "        desc_map = {\n",
    "            \"Green_Excess\": \"√çndice de 'Verdosidad' (G - (R+B)/2)\",\n",
    "            \"Green_Texture\": \"Interacci√≥n Verde * Textura\",\n",
    "            \"Spatial_Radial\": \"Distancia al centro del cerebro\",\n",
    "            \"A\": \"Canal A (LAB) - Rojo/Verde\",\n",
    "            \"B_lab\": \"Canal B (LAB) - Azul/Amarillo\",\n",
    "            \"Texture_LocalStd\": \"Complejidad/Rugosidad local\",\n",
    "            \"Symmetry\": \"Diferencia entre hemisferios\"\n",
    "        }\n",
    "        \n",
    "        for i, (name, imp) in enumerate(feat_imps):\n",
    "            desc = desc_map.get(name, \"-\")\n",
    "            bold = \"**\" if i < 3 else \"\"\n",
    "            f.write(f\"| {i+1} | {bold}{name}{bold} | {imp:.4f} | {desc} |\\n\")\n",
    "            \n",
    "        f.write(f\"\\n### 4. Resultados Finales (Test Set - {params['n_test']} im√°genes)\\n\")\n",
    "        f.write(f\"#### üìä Clasificaci√≥n de Im√°genes\\n\")\n",
    "        f.write(f\"- ‚úÖ **TP (Detectados):** {metrics['TP']} im√°genes - *El modelo encontr√≥ el tumor correctamente.*\\n\")\n",
    "        f.write(f\"- ‚úÖ **TN (Sanos):** {metrics['TN']} im√°genes - *El modelo confirm√≥ que estaba sano.*\\n\")\n",
    "        f.write(f\"- ‚ùå **FP (Falsas Alarmas):** {metrics['FP']} im√°genes - *El modelo vio tumor donde no hab√≠a.*\\n\")\n",
    "        f.write(f\"- ‚ùå **FN (Perdidos):** {metrics['FN']} im√°genes - *El modelo NO vio el tumor existente.*\\n\")\n",
    "        \n",
    "        f.write(f\"\\n#### üéØ Precisi√≥n Quir√∫rgica (P√≠xel a P√≠xel)\\n\")\n",
    "        f.write(f\"- **Sensibilidad (Recall):** `{metrics['Recall']:.2%}`\\n\")\n",
    "        f.write(f\"  > De todo el tejido tumoral real, el modelo detect√≥ este porcentaje.\\n\")\n",
    "        f.write(f\"- **Confianza (Precision):** `{metrics['Precision']:.2%}`\\n\")\n",
    "        f.write(f\"  > De todo lo que el modelo marc√≥ en rojo, este porcentaje era realmente tumor.\\n\")\n",
    "        f.write(f\"- **Calidad de Segmentaci√≥n (Dice):** `{metrics['Dice']:.2%}`\\n\")\n",
    "        f.write(f\"- **Limpieza de Ruido:** Se eliminaron **{metrics['NoiseReduced']:,}** p√≠xeles de falsas alarmas durante el post-proceso.\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    print(f\"\\n[HISTORIAL] Resultados detallados guardados en: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. FUNCIONES DE PREPROCESAMIENTO\n",
    "# ==========================================\n",
    "def apply_clahe(img):\n",
    "    \"\"\"Mejora de contraste adaptativa (CLAHE) en canal L (LAB).\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l_clahe, a, b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def apply_denoise(img):\n",
    "    \"\"\"Filtro de Mediana para eliminar ruido 'sal y pimienta'.\"\"\"\n",
    "    return cv2.medianBlur(img, 3)\n",
    "\n",
    "def align_brain(img, mask=None):\n",
    "    \"\"\"\n",
    "    Alineaci√≥n geom√©trica basada en PCA.\n",
    "    Rota el cerebro para que el eje mayor sea vertical.\n",
    "    Corrige orientaci√≥n invertida usando heur√≠stica de masa.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    puntos = np.column_stack(np.where(thresh > 0)) # (y, x)\n",
    "    \n",
    "    if len(puntos) == 0:\n",
    "        return (img, mask) if mask is not None else img\n",
    "\n",
    "    # PCA Compute\n",
    "    mean, eigenvectors, _ = cv2.PCACompute2(puntos.astype(np.float32), mean=None)\n",
    "    center_img = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "    center_brain = (mean[0, 1], mean[0, 0])\n",
    "    \n",
    "    # √Ångulo y Rotaci√≥n Base\n",
    "    angle = np.arctan2(eigenvectors[0, 1], eigenvectors[0, 0])\n",
    "    rotation_angle = np.degrees(angle)\n",
    "    \n",
    "    # Forzar verticalidad\n",
    "    if abs(rotation_angle) < 45: \n",
    "        rotation_angle += 90\n",
    "        \n",
    "    M = cv2.getRotationMatrix2D(center_brain, rotation_angle, 1.0)\n",
    "    # Ajuste de traslaci√≥n para centrar\n",
    "    M[0, 2] += center_img[0] - center_brain[0]\n",
    "    M[1, 2] += center_img[1] - center_brain[1]\n",
    "    \n",
    "    # Verificaci√≥n de Orientaci√≥n (Arriba vs Abajo)\n",
    "    h, w = img.shape[:2]\n",
    "    img_temp = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    \n",
    "    gray_aligned = cv2.cvtColor(img_temp, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh_a = cv2.threshold(gray_aligned, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Heur√≠stica: Si la mitad inferior tiene mucha m√°s masa, est√° invertido\n",
    "    if np.sum(thresh_a[h//2:, :]) > np.sum(thresh_a[:h//2, :]) * 1.1:\n",
    "        rotation_angle += 180\n",
    "        M = cv2.getRotationMatrix2D(center_brain, rotation_angle, 1.0)\n",
    "        M[0, 2] += center_img[0] - center_brain[0]\n",
    "        M[1, 2] += center_img[1] - center_brain[1]\n",
    "\n",
    "    # Transformaci√≥n Final\n",
    "    img_aligned = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    if mask is not None:\n",
    "        mask_aligned = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "        return img_aligned, mask_aligned\n",
    "        \n",
    "    return img_aligned\n",
    "\n",
    "def eliminar_cerebelo_y_ruido(img_input, pred_binaria):\n",
    "    \"\"\"\n",
    "    Limpieza post-predicci√≥n (Morphology + Size Filter).\n",
    "    Nota: Se elimin√≥ el recorte fijo del 40%; el modelo ahora infiere la ubicaci√≥n.\n",
    "    \"\"\"\n",
    "    # 1. M√°scara del cerebro (ROI)\n",
    "    if len(img_input.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_input, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img_input\n",
    "        \n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    brain_mask = np.zeros_like(pred_binaria)\n",
    "    if len(contours) > 0:\n",
    "        cv2.drawContours(brain_mask, [max(contours, key=cv2.contourArea)], -1, 1, -1)\n",
    "        brain_mask = cv2.erode(brain_mask, np.ones((5,5), np.uint8), iterations=2)\n",
    "\n",
    "    # 2. Aplicar ROI\n",
    "    cleaned = cv2.bitwise_and(pred_binaria, pred_binaria, mask=brain_mask)\n",
    "\n",
    "    # 3. Filtrar manchas peque√±as (<50 px)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(cleaned.astype(np.uint8))\n",
    "    output = np.zeros_like(cleaned)\n",
    "    for i in range(1, num):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= 50:\n",
    "            output[labels == i] = 1\n",
    "\n",
    "    # 4. Suavizado Morfol√≥gico\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    output = cv2.morphologyEx(output.astype(np.uint8), cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    return cv2.morphologyEx(output, cv2.MORPH_CLOSE, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. INGENIER√çA DE CARACTER√çSTICAS\n",
    "# ==========================================\n",
    "def get_symmetry_feature(img):\n",
    "    \"\"\"Mapa de diferencia absoluto entre hemisferios (asume alineaci√≥n vertical).\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.absdiff(gray, cv2.flip(gray, 1))\n",
    "\n",
    "def extract_features(img):\n",
    "    \"\"\"\n",
    "    Genera un vector de caracter√≠sticas para cada p√≠xel.\n",
    "    Features: RGB, HSV, LAB, Bordes, Textura Local, Espaciales, Simetr√≠a, Interacci√≥n Verde.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    # --- Color ---\n",
    "    df['R'] = img[:, :, 2].reshape(-1)\n",
    "    df['G'] = img[:, :, 1].reshape(-1)\n",
    "    df['B'] = img[:, :, 0].reshape(-1)\n",
    "    \n",
    "    # Feature cr√≠tica: Green Excess (G - avg(R,B))\n",
    "    # Discrimina 'verde artefacto' de 'verde tejido'\n",
    "    df['Green_Excess'] = df['G'].astype(np.float32) - (df['R'].astype(np.float32) + df['B'].astype(np.float32)) / 2.0\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    df['H'] = img_hsv[:, :, 0].reshape(-1)\n",
    "    df['S'] = img_hsv[:, :, 1].reshape(-1)\n",
    "    df['V'] = img_hsv[:, :, 2].reshape(-1)\n",
    "\n",
    "    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    df['L'] = img_lab[:, :, 0].reshape(-1)\n",
    "    df['A'] = img_lab[:, :, 1].reshape(-1)\n",
    "    df['B_lab'] = img_lab[:, :, 2].reshape(-1)\n",
    "\n",
    "    # --- Textura ---\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    df['Canny'] = cv2.Canny(img_gray, 100, 200).reshape(-1)\n",
    "    df['Gaussian'] = nd.gaussian_filter(img_gray, sigma=3).reshape(-1)\n",
    "    \n",
    "    sobel_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    df['Sobel_Mag'] = np.sqrt(sobel_x**2 + sobel_y**2).reshape(-1)\n",
    "\n",
    "    # Desviaci√≥n Est√°ndar Local (Proxy de Entrop√≠a/Complejidad)\n",
    "    img_f = img_gray.astype(np.float32)\n",
    "    mu = cv2.blur(img_f, (5, 5))\n",
    "    mu2 = cv2.blur(img_f**2, (5, 5))\n",
    "    sigma = np.sqrt(np.maximum(mu2 - mu**2, 0))\n",
    "    df['Texture_LocalStd'] = sigma.reshape(-1)\n",
    "\n",
    "    # --- Interacci√≥n ---\n",
    "    # Green * Texture: Ayuda a diferenciar ruido verde (liso) de tumor verde (rugoso)\n",
    "    df['Green_Texture'] = df['Green_Excess'] * df['Texture_LocalStd']\n",
    "\n",
    "    # --- Espaciales ---\n",
    "    y, x = np.mgrid[0:h, 0:w]\n",
    "    df['Spatial_Y'] = (y / h).astype(np.float32).reshape(-1)\n",
    "    df['Spatial_X'] = (x / w).astype(np.float32).reshape(-1)\n",
    "    df['Spatial_Radial'] = np.sqrt((df['Spatial_Y'] - 0.5)**2 + (df['Spatial_X'] - 0.5)**2)\n",
    "\n",
    "    # --- Simetr√≠a ---\n",
    "    df['Symmetry'] = get_symmetry_feature(img).reshape(-1)\n",
    "\n",
    "    return df, (h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. METRICAS Y EVALUACI√ìN\n",
    "# ==========================================\n",
    "def calcular_metricas(y_true, y_pred):\n",
    "    \"\"\"Calcula m√©tricas a nivel de p√≠xel.\"\"\"\n",
    "    true_flat = y_true.reshape(-1)\n",
    "    pred_flat = y_pred.reshape(-1)\n",
    "    \n",
    "    tp = np.sum((true_flat == 1) & (pred_flat == 1))\n",
    "    fp = np.sum((true_flat == 0) & (pred_flat == 1))\n",
    "    fn = np.sum((true_flat == 1) & (pred_flat == 0))\n",
    "    tn = np.sum((true_flat == 0) & (pred_flat == 0))\n",
    "    \n",
    "    total_pos = tp + fn\n",
    "    total_det = tp + fp\n",
    "    \n",
    "    recall = tp / total_pos if total_pos > 0 else 0.0\n",
    "    precision = tp / total_det if total_det > 0 else 0.0\n",
    "    iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0\n",
    "    dice = 2*tp / (2*tp + fp + fn) if (2*tp + fp + fn) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"TP\": tp, \"FP\": fp, \"FN\": fn, \"TN\": tn,\n",
    "        \"Recall\": recall, \"Precision\": precision, \"IoU\": iou, \"Dice\": dice\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO PIPELINE DE DETECCI√ìN DE TUMORES ===\n",
      "\n",
      "[1] Buscando Dataset...\n",
      "    -> Encontrado: c:\\UAB\\3¬∫ 1¬∫\\APC\\Tumor-Tracer\\data\\dataset_plano (3929 m√°scaras)\n",
      "    -> Seleccionadas 500 im√°genes para el proceso.\n",
      "    -> Train: 400 | Test: 100\n",
      "\n",
      "[2] Extracci√≥n de Caracter√≠sticas (Train)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:14<00:00, 28.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Tiempo Extracci√≥n: 14.3s\n",
      "    -> Dataset Final: 1,616,772 p√≠xeles.\n",
      "    -> Distribuci√≥n: Tumor=274,693, Fondo=1,342,079\n",
      "\n",
      "[3] Validaci√≥n Cruzada (K-Fold=7)...\n",
      "    -> Resultados por Fold:\n",
      "       Fold  F1         Precision  Recall    \n",
      "       -----------------------------------\n",
      "       1     0.8937     0.9087     0.8792    \n",
      "       2     0.8967     0.9147     0.8794    \n",
      "       3     0.8864     0.9099     0.8640    \n",
      "       4     0.8908     0.9014     0.8805    \n",
      "       5     0.8986     0.9048     0.8926    \n",
      "       6     0.8948     0.9109     0.8792    \n",
      "       7     0.8953     0.9091     0.8820    \n",
      "       -----------------------------------\n",
      "    -> PROMEDIOS:\n",
      "       F1-Score  : 0.8938 (+/- 0.0075)\n",
      "       Precision : 0.9085\n",
      "       Recall    : 0.8796\n",
      "    -> Estado: ‚úÖ ESTABLE\n",
      "\n",
      "[4] Entrenando Modelo Final...\n",
      "\n",
      "    -> IMPORTANCIA DE CARACTER√çSTICAS (Todas):\n",
      "       Ranking  Feature              Importancia\n",
      "       ----------------------------------------\n",
      "       1        A                    : 0.1431\n",
      "       2        Green_Excess         : 0.1391\n",
      "       3        Spatial_Radial       : 0.1015\n",
      "       4        Green_Texture        : 0.0981\n",
      "       5        B_lab                : 0.0655\n",
      "       6        Gaussian             : 0.0543\n",
      "       7        G                    : 0.0528\n",
      "       8        Spatial_X            : 0.0457\n",
      "       9        L                    : 0.0381\n",
      "       10       Spatial_Y            : 0.0364\n",
      "       11       H                    : 0.0344\n",
      "       12       R                    : 0.0341\n",
      "       13       B                    : 0.0335\n",
      "       14       S                    : 0.0333\n",
      "       15       Texture_LocalStd     : 0.0302\n",
      "       16       V                    : 0.0240\n",
      "       17       Symmetry             : 0.0182\n",
      "       18       Sobel_Mag            : 0.0165\n",
      "       19       Canny                : 0.0011\n",
      "\n",
      "[5] Evaluando en Test Set (100 im√°genes)...\n",
      "Directorio de resultados preparado: c:\\UAB\\3¬∫ 1¬∫\\APC\\Tumor-Tracer\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencia: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:54<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REPORTE FINAL DE EJECUCI√ìN\n",
      "============================================================\n",
      "1. CLASIFICACI√ìN DE IM√ÅGENES\n",
      "   Total: 100\n",
      "   ‚úÖ TP:  32 (32.00%)\n",
      "   ‚úÖ TN:  38 (38.00%)\n",
      "   ‚ùå FP:  29 (29.00%)\n",
      "   ‚ùå FN:   1 ( 1.00%)\n",
      "\n",
      "2. CALIDAD DE SEGMENTACI√ìN (Casos TP)\n",
      "   Dice Promedio: 69.33%\n",
      "\n",
      "3. PRECISI√ìN QUIR√öRGICA (P√≠xeles)\n",
      "   Sensibilidad (Recall): 74.25%\n",
      "   Confianza (Precision): 58.51%\n",
      "   Ruido Eliminado:       58,627 p√≠xeles\n",
      "\n",
      "4. TIEMPOS DE EJECUCI√ìN\n",
      "   Extracci√≥n (Train): 14.27 s\n",
      "   Cross-Validation:   22.62 s\n",
      "   Entrenamiento:      111.89 s\n",
      "   Inferencia (Test):  54.84 s\n",
      "   TOTAL SCRIPT:       204.68 s\n",
      "\n",
      "[HISTORIAL] Resultados detallados guardados en: experiment_history.md\n",
      "\n",
      "[FIN] Resultados guardados en 'results/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. PIPELINE PRINCIPAL (MAIN)\n",
    "# ==========================================\n",
    "t_start_total = time.time()\n",
    "timings = {}\n",
    "\n",
    "print(\"\\n=== INICIANDO PIPELINE DE DETECCI√ìN DE TUMORES ===\")\n",
    "\n",
    "# --- 1. Buscar Datos ---\n",
    "print(\"\\n[1] Buscando Dataset...\")\n",
    "search_paths = [\n",
    "    os.path.join(PROJECT_ROOT, \"data\", \"dataset_plano\"),\n",
    "    os.path.join(PROJECT_ROOT, \"data\", \"kaggle_3m\")\n",
    "]\n",
    "\n",
    "files_found = []\n",
    "for p in search_paths:\n",
    "    if os.path.exists(p):\n",
    "        curr = glob.glob(os.path.join(p, '**', '*_mask.tif'), recursive=True)\n",
    "        if curr:\n",
    "            files_found = curr\n",
    "            print(f\"    -> Encontrado: {p} ({len(curr)} m√°scaras)\")\n",
    "            break\n",
    "\n",
    "if not files_found:\n",
    "    print(\"[ERROR] No se encontraron datos. Revise las rutas.\")\n",
    "else:\n",
    "    # Preparar pares validos\n",
    "    valid_pairs = []\n",
    "    for mask_p in files_found:\n",
    "        img_p = mask_p.replace('_mask.tif', '.tif')\n",
    "        if os.path.exists(img_p):\n",
    "            valid_pairs.append((img_p, mask_p))\n",
    "\n",
    "    # Selecci√≥n Aleatoria\n",
    "    sample_size = min(500, len(valid_pairs))\n",
    "    random.seed(RANDOM_STATE)\n",
    "    selected = random.sample(valid_pairs, sample_size)\n",
    "    print(f\"    -> Seleccionadas {len(selected)} im√°genes para el proceso.\")\n",
    "\n",
    "    # Split Train/Test\n",
    "    train_pairs, test_pairs = train_test_split(selected, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    print(f\"    -> Train: {len(train_pairs)} | Test: {len(test_pairs)}\")\n",
    "\n",
    "    # --- 2. Extracci√≥n de Features (Entrenamiento) ---\n",
    "    print(f\"\\n[2] Extracci√≥n de Caracter√≠sticas (Train)...\")\n",
    "    t_start_extract = time.time()\n",
    "    X_train_list, Y_train_list = [], []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for img_p, mask_p in tqdm(train_pairs, desc=\"Procesando Train\"):\n",
    "        img = cv2_imread_unicode(img_p)\n",
    "        mask = cv2_imread_unicode(mask_p, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None or mask is None: continue\n",
    "\n",
    "        # Pipeline Preproceso\n",
    "        img = apply_clahe(img)\n",
    "        img = apply_denoise(img)\n",
    "        img, mask = align_brain(img, mask)\n",
    "\n",
    "        mask = (mask // 255).reshape(-1)\n",
    "        features, _ = extract_features(img)\n",
    "        features = features.astype(np.float32)\n",
    "\n",
    "        # Subsampling estrategico\n",
    "        idx_tumor = np.where(mask == 1)[0]\n",
    "        idx_backg = np.where(mask == 0)[0]\n",
    "        \n",
    "        counts_t = len(idx_tumor)\n",
    "        counts_b = len(idx_backg)\n",
    "        \n",
    "        sample_indices = []\n",
    "        if counts_t > 0:\n",
    "            # Tomar todo el tumor y 3x de fondo\n",
    "            needed_b = min(counts_b, counts_t * SUBSAMPLE_RATIO)\n",
    "            if needed_b > 0:\n",
    "                sample_indices = np.concatenate([\n",
    "                    idx_tumor, \n",
    "                    np.random.choice(idx_backg, needed_b, replace=False)\n",
    "                ])\n",
    "            else:\n",
    "                sample_indices = idx_tumor\n",
    "        else:\n",
    "            # Imagen sana: tomar peque√±a muestra representativa\n",
    "            sample_indices = np.random.choice(idx_backg, min(counts_b, 2000), replace=False)\n",
    "\n",
    "        X_train_list.append(features.iloc[sample_indices])\n",
    "        Y_train_list.append(mask[sample_indices])\n",
    "\n",
    "    time_extract = time.time() - t_start_extract\n",
    "    timings['extraction'] = time_extract\n",
    "    print(f\"    -> Tiempo Extracci√≥n: {time_extract:.1f}s\")\n",
    "    \n",
    "    # Consolidar\n",
    "    X_train = pd.concat(X_train_list)\n",
    "    Y_train = np.concatenate(Y_train_list)\n",
    "    del X_train_list, Y_train_list\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"    -> Dataset Final: {len(X_train):,} p√≠xeles.\")\n",
    "    print(f\"    -> Distribuci√≥n: Tumor={np.sum(Y_train==1):,}, Fondo={np.sum(Y_train==0):,}\")\n",
    "\n",
    "    # --- 3. Validaci√≥n Cruzada ---\n",
    "    print(f\"\\n[3] Validaci√≥n Cruzada (K-Fold={CV_FOLDS})...\")\n",
    "    t_start_cv = time.time()\n",
    "    # Muestra reducida para CV rapido\n",
    "    cv_idx = np.random.choice(len(Y_train), min(100000, len(Y_train)), replace=False)\n",
    "    \n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=RF_ESTIMATORS,\n",
    "        max_depth=RF_MAX_DEPTH,\n",
    "        class_weight=RF_CLASS_WEIGHT,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    \n",
    "    kfold = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    # Usamos cross_validate para obtener m√∫ltiples m√©tricas\n",
    "    scoring_metrics = ['f1', 'precision', 'recall']\n",
    "    scores = cross_validate(rf_model, X_train.iloc[cv_idx], Y_train[cv_idx], cv=kfold, scoring=scoring_metrics, n_jobs=1)\n",
    "    \n",
    "    print(f\"    -> Resultados por Fold:\")\n",
    "    print(f\"       {'Fold':<5} {'F1':<10} {'Precision':<10} {'Recall':<10}\")\n",
    "    print(f\"       {'-'*35}\")\n",
    "    \n",
    "    for i in range(CV_FOLDS):\n",
    "        f1 = scores['test_f1'][i]\n",
    "        prec = scores['test_precision'][i]\n",
    "        rec = scores['test_recall'][i]\n",
    "        print(f\"       {i+1:<5d} {f1:<10.4f} {prec:<10.4f} {rec:<10.4f}\")\n",
    "        \n",
    "    print(f\"       {'-'*35}\")\n",
    "    print(f\"    -> PROMEDIOS:\")\n",
    "    print(f\"       F1-Score  : {scores['test_f1'].mean():.4f} (+/- {scores['test_f1'].std()*2:.4f})\")\n",
    "    print(f\"       Precision : {scores['test_precision'].mean():.4f}\")\n",
    "    print(f\"       Recall    : {scores['test_recall'].mean():.4f}\")\n",
    "    \n",
    "    stability = scores['test_f1'].std() < 0.05\n",
    "    print(f\"    -> Estado: {'‚úÖ ESTABLE' if stability else '‚ö†Ô∏è INESTABLE'}\")\n",
    "\n",
    "    time_cv = time.time() - t_start_cv\n",
    "    timings['cv'] = time_cv\n",
    "\n",
    "    # --- 4. Entrenamiento Final ---\n",
    "    print(f\"\\n[4] Entrenando Modelo Final...\")\n",
    "    t_start_train = time.time()\n",
    "    rf_model.fit(X_train, Y_train)\n",
    "    time_train = time.time() - t_start_train\n",
    "    timings['train'] = time_train\n",
    "\n",
    "    \n",
    "    # Importancias\n",
    "    imps = rf_model.feature_importances_\n",
    "    feat_names = X_train.columns\n",
    "    sorted_idx = np.argsort(imps)[::-1]\n",
    "    \n",
    "    # Guardar lista de features para el reporte\n",
    "    feature_importance_list = []\n",
    "    \n",
    "    print(\"\\n    -> IMPORTANCIA DE CARACTER√çSTICAS (Todas):\")\n",
    "    print(f\"       {'Ranking':<8} {'Feature':<20} {'Importancia':<10}\")\n",
    "    print(f\"       {'-'*40}\")\n",
    "    for i in range(len(feat_names)):\n",
    "        idx = sorted_idx[i]\n",
    "        name = feat_names[idx]\n",
    "        val = imps[idx]\n",
    "        feature_importance_list.append((name, val))\n",
    "        print(f\"       {i+1:<8d} {name:<20s} : {val:.4f}\")\n",
    "\n",
    "    # --- 5. Inferencia y Evaluaci√≥n (Test) ---\n",
    "    print(f\"\\n[5] Evaluando en Test Set ({len(test_pairs)} im√°genes)...\")\n",
    "    results_dir = os.path.join(PROJECT_ROOT, \"results\")\n",
    "    limpiar_directorio_resultados(results_dir)\n",
    "    \n",
    "    global_metrics = {\"TP\":0, \"FP\":0, \"FN\":0, \"TN\":0}\n",
    "    img_counts = {\"TP\":0, \"TN\":0, \"FP\":0, \"FN\":0}\n",
    "    tp_qualities = [] # Dice scores\n",
    "\n",
    "    metrics_raw = {\"TP\":0, \"FP\":0, \"FN\":0} # Antes de limpiar\n",
    "    \n",
    "    total_cleaned_pixels = 0\n",
    "    \n",
    "    t_start_inf = time.time()\n",
    "    for img_p, mask_p in tqdm(test_pairs, desc=\"Inferencia\"):\n",
    "\n",
    "        img_orig = cv2_imread_unicode(img_p)\n",
    "        mask_orig = cv2_imread_unicode(mask_p, cv2.IMREAD_GRAYSCALE)\n",
    "        fname = os.path.basename(img_p)\n",
    "        \n",
    "        if img_orig is None: continue\n",
    "\n",
    "        # Preproceso Test\n",
    "        img = apply_clahe(img_orig)\n",
    "        img = apply_denoise(img)\n",
    "        img, mask = align_brain(img, mask_orig)\n",
    "        mask_bin = (mask // 255).astype(np.uint8)\n",
    "\n",
    "        # Prediccion\n",
    "        feat_df, (h, w) = extract_features(img)\n",
    "        pred_flat = rf_model.predict(feat_df)\n",
    "        pred_map = pred_flat.reshape(h, w).astype(np.uint8)\n",
    "        \n",
    "        # Guardar metricas RAW\n",
    "        m_raw = calcular_metricas(mask_bin, pred_map)\n",
    "        metrics_raw[\"FP\"] += m_raw[\"FP\"]\n",
    "\n",
    "        # Limpieza\n",
    "        clean_map = eliminar_cerebelo_y_ruido(img, pred_map)\n",
    "        \n",
    "        # Metricas FINALES\n",
    "        m_final = calcular_metricas(mask_bin, clean_map)\n",
    "        total_cleaned_pixels += (m_raw[\"FP\"] - m_final[\"FP\"])\n",
    "        \n",
    "        # Acumular globales\n",
    "        for k in global_metrics: global_metrics[k] += m_final[k]\n",
    "        \n",
    "        # Clasificar Imagen\n",
    "        has_tumor = np.sum(mask_bin) > 0\n",
    "        detected = np.sum(clean_map) > 0\n",
    "        cat = \"TN\"\n",
    "        if has_tumor and detected: cat = \"TP\"\n",
    "        elif has_tumor and not detected: cat = \"FN\"\n",
    "        elif not has_tumor and detected: cat = \"FP\"\n",
    "        \n",
    "        img_counts[cat] += 1\n",
    "        \n",
    "        # Guardar (Solo TP o errores FP/FN interesante guardar)\n",
    "        # Gestionar carpetas din√°micas para TP\n",
    "        save_subdir = cat\n",
    "        extra_txt = \"\"\n",
    "        \n",
    "        if cat == \"TP\":\n",
    "            dice = m_final[\"Dice\"]\n",
    "            tp_qualities.append(dice)\n",
    "            decile = min(int(dice * 10), 9) * 10\n",
    "            save_subdir = os.path.join(\"TP\", f\"Dice_{decile:02d}_{decile+10:02d}\")\n",
    "            os.makedirs(os.path.join(results_dir, save_subdir), exist_ok=True)\n",
    "            extra_txt = f\"Dice: {dice:.2%}\"\n",
    "        elif cat == \"FP\":\n",
    "            extra_txt = f\"Ruido: {m_final['FP']} px\"\n",
    "            \n",
    "        # Generar Plot (Solo guardar)\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        fig.suptitle(f\"[{cat}] {fname} | {extra_txt}\")\n",
    "        axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); axs[0].set_title(\"Input (Aligned)\")\n",
    "        axs[1].imshow(mask_bin, cmap='gray'); axs[1].set_title(\"Ground Truth\")\n",
    "        axs[2].imshow(clean_map, cmap='Reds'); axs[2].set_title(\"Predicci√≥n AI\")\n",
    "        for ax in axs: ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, save_subdir, f\"res_{fname}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    time_inf = time.time() - t_start_inf\n",
    "    timings['inference'] = time_inf\n",
    "    timings['total'] = time.time() - t_start_total\n",
    "\n",
    "    # --- 6. Reporte Final ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REPORTE FINAL DE EJECUCI√ìN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Imagenes\n",
    "    n_test = len(test_pairs)\n",
    "    print(\"1. CLASIFICACI√ìN DE IM√ÅGENES\")\n",
    "    print(f\"   Total: {n_test}\")\n",
    "    print(f\"   ‚úÖ TP: {img_counts['TP']:3d} ({img_counts['TP']/n_test:6.2%})\")\n",
    "    print(f\"   ‚úÖ TN: {img_counts['TN']:3d} ({img_counts['TN']/n_test:6.2%})\")\n",
    "    print(f\"   ‚ùå FP: {img_counts['FP']:3d} ({img_counts['FP']/n_test:6.2%})\")\n",
    "    print(f\"   ‚ùå FN: {img_counts['FN']:3d} ({img_counts['FN']/n_test:6.2%})\")\n",
    "    \n",
    "    # 2. Calidad\n",
    "    print(\"\\n2. CALIDAD DE SEGMENTACI√ìN (Casos TP)\")\n",
    "    avg_dice = np.mean(tp_qualities) if tp_qualities else 0.0\n",
    "    if tp_qualities:\n",
    "        print(f\"   Dice Promedio: {avg_dice:.2%}\")\n",
    "    else:\n",
    "        print(\"   (No hubo casos TP)\")\n",
    "\n",
    "    # 3. Pixeles\n",
    "    print(\"\\n3. PRECISI√ìN QUIR√öRGICA (P√≠xeles)\")\n",
    "    tot_p = global_metrics[\"TP\"] + global_metrics[\"FN\"]\n",
    "    tot_det = global_metrics[\"TP\"] + global_metrics[\"FP\"]\n",
    "    \n",
    "    sens = global_metrics[\"TP\"] / tot_p if tot_p > 0 else 0\n",
    "    conf = global_metrics[\"TP\"] / tot_det if tot_det > 0 else 0\n",
    "    \n",
    "    print(f\"   Sensibilidad (Recall): {sens:6.2%}\")\n",
    "    print(f\"   Confianza (Precision): {conf:6.2%}\")\n",
    "    print(f\"   Ruido Eliminado:       {total_cleaned_pixels:,} p√≠xeles\")\n",
    "    \n",
    "    # 4. Tiempos\n",
    "    print(\"\\n4. TIEMPOS DE EJECUCI√ìN\")\n",
    "    print(f\"   Extracci√≥n (Train): {timings['extraction']:.2f} s\")\n",
    "    print(f\"   Cross-Validation:   {timings['cv']:.2f} s\")\n",
    "    print(f\"   Entrenamiento:      {timings['train']:.2f} s\")\n",
    "    print(f\"   Inferencia (Test):  {timings['inference']:.2f} s\")\n",
    "    print(f\"   TOTAL SCRIPT:       {timings['total']:.2f} s\")\n",
    "\n",
    "    # --- LOG A MARKDOWN ---\n",
    "    params = {\n",
    "        'n_images': len(selected),\n",
    "        'n_train': len(train_pairs),\n",
    "        'n_test': len(test_pairs),\n",
    "        'rf_est': RF_ESTIMATORS,\n",
    "        'rf_depth': RF_MAX_DEPTH,\n",
    "        'rf_weight': str(RF_CLASS_WEIGHT)\n",
    "    }\n",
    "    \n",
    "    metrics = {\n",
    "        'TP': img_counts['TP'], 'TN': img_counts['TN'], 'FP': img_counts['FP'], 'FN': img_counts['FN'],\n",
    "        'Recall': sens, 'Precision': conf, 'Dice': avg_dice,\n",
    "        'NoiseReduced': total_cleaned_pixels,\n",
    "        'cv_f1_mean': scores['test_f1'].mean(),\n",
    "        'cv_f1_std': scores['test_f1'].std(),\n",
    "        'cv_prec_mean': scores['test_precision'].mean(),\n",
    "        'cv_rec_mean': scores['test_recall'].mean()\n",
    "    }\n",
    "    \n",
    "    log_experiment_to_md(params, metrics, timings, scores, feature_importance_list)\n",
    "    \n",
    "    print(\"\\n[FIN] Resultados guardados en 'results/'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
