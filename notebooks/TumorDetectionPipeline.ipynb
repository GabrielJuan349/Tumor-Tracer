{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Tumor Tracer AI - Pipeline de Detecci√≥n de Tumores Cerebrales\n",
    "\n",
    "## üìå Informaci√≥n del Proyecto\n",
    "- **Proyecto:** Tumor-Tracer (Machine Learning Cl√°sico)\n",
    "- **Autores:** Aim√© Moral & Gabriel Juan\n",
    "- **Fecha:** Diciembre 2024\n",
    "- **Versi√≥n:** 2.0\n",
    "- **GitHub:** [GabrielJuan349/Tumor-Tracer](https://github.com/GabrielJuan349/Tumor-Tracer)\n",
    "\n",
    "## üéØ Objetivo\n",
    "Segmentaci√≥n autom√°tica de tumores cerebrales (gliomas) en im√°genes de resonancia magn√©tica (MRI) \n",
    "usando **Random Forest** con ingenier√≠a de caracter√≠sticas avanzada.\n",
    "\n",
    "## üìä Dataset\n",
    "- **Fuente:** [LGG MRI Segmentation (Kaggle)](https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation)\n",
    "- **Im√°genes:** 3,929 MRI FLAIR + m√°scaras binarias\n",
    "- **Resoluci√≥n:** 256x256 p√≠xeles\n",
    "- **Formato:** TIF (8-bit grayscale/RGB)\n",
    "\n",
    "## üîß Stack Tecnol√≥gico\n",
    "- `scikit-learn` - Random Forest Classifier\n",
    "- `OpenCV` - Procesamiento de im√°genes\n",
    "- `NumPy/Pandas` - Manipulaci√≥n de datos\n",
    "- `Matplotlib` - Visualizaci√≥n\n",
    "\n",
    "## üìà M√©tricas Objetivo\n",
    "- **Sensibilidad (Recall):** >85% (detectar todos los tumores)\n",
    "- **Precisi√≥n:** >75% (minimizar falsas alarmas)\n",
    "- **Dice Score:** >70% (calidad de segmentaci√≥n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß¨ Metodolog√≠a\n",
    "\n",
    "### Pipeline de 5 Etapas\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[MRI Input<br/>(256x256)] --> B[Preproceso<br/>(CLAHE+PCA)]\n",
    "    B --> C[Features<br/>(21 dims)]\n",
    "    C --> D[Random Forest]\n",
    "    D --> E[Post-Proceso]\n",
    "```\n",
    "\n",
    "### 1Ô∏è‚É£ **Preprocesamiento Avanzado**\n",
    "- **CLAHE:** Mejora de contraste adaptativo\n",
    "- **Denoise:** Filtro mediana (reduce artefactos de adquisici√≥n)\n",
    "- **Alineaci√≥n PCA:** Normalizaci√≥n geom√©trica (rotaci√≥n vertical)\n",
    "\n",
    "### 2Ô∏è‚É£ **Ingenier√≠a de Caracter√≠sticas (21 features)**\n",
    "\n",
    "| Categor√≠a | Features | Justificaci√≥n Cl√≠nica |\n",
    "|-----------|----------|----------------------|\n",
    "| **Color** | RGB, HSV, LAB, Green_Excess | Los gliomas muestran hiperintensidad variable en FLAIR |\n",
    "| **Textura** | Sobel, Canny, LocalStd | Tumores tienen bordes irregulares y heterogeneidad interna |\n",
    "| **Espacial** | Radial, X, Y | Localizaci√≥n anat√≥mica (evita cerebelo) |\n",
    "| **Simetr√≠a** | AbsDiff L/R | Lesiones asim√©tricas son sospechosas |\n",
    "| **Interacci√≥n** | Green√óTexture | Discrimina artefactos de tejido patol√≥gico |\n",
    "\n",
    "### 3Ô∏è‚É£ **Estrategia de Muestreo**\n",
    "- **Problema:** Dataset desbalanceado (~98% fondo, ~2% tumor)\n",
    "- **Soluci√≥n:** Ratio 1:3 (1 p√≠xel tumor : 3 p√≠xeles fondo)\n",
    "- **Resultado:** ~500K p√≠xeles entrenamiento (de ~100M totales)\n",
    "\n",
    "### 4Ô∏è‚É£ **Modelo: Random Forest**\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    n_estimators=100,      # 100 √°rboles de decisi√≥n\n",
    "    max_depth=30,          # Profundidad m√°xima para evitar overfitting\n",
    "    class_weight={0:1, 1:1.5},  # Penaliza m√°s los falsos negativos (cr√≠tico en medicina)\n",
    "    n_jobs=-1              # Paralelizaci√≥n total\n",
    ")\n",
    "```\n",
    "\n",
    "**¬øPor qu√© Random Forest?**\n",
    "- ‚úÖ Robusto a outliers (artefactos de MRI)\n",
    "- ‚úÖ Interpretable (importancia de caracter√≠sticas)\n",
    "- ‚úÖ No requiere GPU (reproducible en cualquier hardware)\n",
    "- ‚úÖ Validaci√≥n OOB autom√°tica\n",
    "\n",
    "### 5Ô∏è‚É£ **Post-Procesamiento**\n",
    "1. **Morfolog√≠a:** Opening (elimina ruido puntual)\n",
    "2. **Filtro de √Årea:** Descarta componentes <50px\n",
    "3. **ROI Brain Mask:** Elimina predicciones fuera del cerebro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports cargados correctamente\n",
      "   - OpenCV: 4.11.0\n",
      "   - NumPy:  2.3.5\n",
      "   - scikit-learn: 1.7.2\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# IMPORTS Y CONFIGURACI√ìN DEL ENTORNO\n",
    "# ==========================================\n",
    "\n",
    "# --- Utilidades Core ---\n",
    "import os                    # Gesti√≥n de rutas y archivos\n",
    "import sys                   # Detecci√≥n de entorno (Kaggle/Local)\n",
    "import glob                  # B√∫squeda recursiva de archivos\n",
    "import random                # Selecci√≥n aleatoria de im√°genes\n",
    "import time                  # Medici√≥n de tiempos\n",
    "import gc                    # Gesti√≥n de memoria (liberaci√≥n manual)\n",
    "import shutil                # Operaciones de carpetas\n",
    "import datetime              # Timestamp para logs\n",
    "\n",
    "# --- An√°lisis de Datos ---\n",
    "import pandas as pd          # DataFrame para features (21 columnas √ó N p√≠xeles)\n",
    "import numpy as np           # Operaciones vectorizadas (10x m√°s r√°pido que Python puro)\n",
    "\n",
    "# --- Procesamiento de Im√°genes ---\n",
    "import cv2                   # OpenCV: CLAHE, morfolog√≠a, PCA\n",
    "from scipy import ndimage as nd  # Filtros gaussianos y operaciones ND\n",
    "\n",
    "# --- Machine Learning ---\n",
    "from sklearn.ensemble import RandomForestClassifier  # Modelo principal\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,        # Split 80/20 train/test\n",
    "    cross_validate,          # K-Fold con m√∫ltiples m√©tricas\n",
    "    KFold                    # Generador de folds\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,          # M√©trica general (no ideal para segmentaci√≥n)\n",
    "    f1_score,                # Balance Precision/Recall\n",
    "    precision_score,         # Confianza de las predicciones\n",
    "    recall_score             # Sensibilidad (cr√≠tico en medicina)\n",
    ")\n",
    "\n",
    "# --- Visualizaci√≥n ---\n",
    "import matplotlib            # Control de backend (Agg para headless)\n",
    "matplotlib.use('Agg')        # Sin ventanas emergentes (estabilidad en Windows/Kaggle)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Progress Bars ---\n",
    "from tqdm import tqdm        # Barras de progreso para loops largos\n",
    "\n",
    "# --- Advertencias ---\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)  # Suprimir warnings de sklearn\n",
    "\n",
    "print(\"‚úÖ Imports cargados correctamente\")\n",
    "print(f\"   - OpenCV: {cv2.__version__}\")\n",
    "print(f\"   - NumPy:  {np.__version__}\")\n",
    "print(f\"   - scikit-learn: {__import__('sklearn').__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Configuraci√≥n del Experimento\n",
    "\n",
    "Para abordar el desbalanceo de clases y la variabilidad de las resonancias magn√©ticas, hemos definido los siguientes hiperpar√°metros estrat√©gicos:\n",
    "\n",
    "### üå≤ Configuraci√≥n del Random Forest\n",
    "*   **`n_estimators = 100`**: Cantidad de √°rboles de decisi√≥n. Un n√∫mero mayor reduce la varianza pero aumenta el costo computacional.\n",
    "*   **`max_depth = 30`**: Profundidad m√°xima. Limitamos esto para evitar que el modelo memorice el ruido de entrenamiento (*overfitting*).\n",
    "*   **`class_weight = {0: 1.0, 1: 1.5}`**: **Justificaci√≥n Cl√≠nica**. Asignamos un peso mayor (1.5x) a la clase \"Tumor\".\n",
    "    *   *Raz√≥n:* En medicina, un **Falso Negativo** (no detectar un tumor existente) es mucho m√°s grave que un Falso Positivo. Forzamos al modelo a ser m√°s sensible.\n",
    "\n",
    "### ‚öñÔ∏è Estrategia de Muestreo (Subsampling)\n",
    "El dataset original tiene una proporci√≥n de p√≠xeles de ~98% Fondo vs ~2% Tumor. Entrenar con esto har√≠a que el modelo prediga siempre \"Fondo\".\n",
    "*   **Ratio 1:3**: Por cada p√≠xel de tumor, seleccionamos aleatoriamente solo 3 p√≠xeles de fondo.\n",
    "*   **Resultado**: Un dataset de entrenamiento equilibrado (~500k p√≠xeles) que cabe en RAM y permite un aprendizaje efectivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURACI√ìN Y CONSTANTES\n",
    "# ==========================================\n",
    "RANDOM_STATE = 42\n",
    "RF_ESTIMATORS = 100\n",
    "RF_MAX_DEPTH = 30\n",
    "RF_CLASS_WEIGHT = {0: 1, 1: 1.5} # Peso 1.5 a Tumor para priorizar sensibilidad sin disparar FPs\n",
    "SUBSAMPLE_RATIO = 3  # Ratio 1 pixel tumor : 3 pixeles fondo\n",
    "CV_FOLDS = 7\n",
    "NUM_IMAGES = 3929\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(BASE_DIR) if \"notebooks\" in BASE_DIR else BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. FUNCIONES DE LECTURA E I/O\n",
    "# ==========================================\n",
    "def cv2_imread_unicode(path, flag=cv2.IMREAD_COLOR):\n",
    "    \"\"\"\n",
    "    Lee im√°genes con rutas que contienen caracteres Unicode (√±, √°, etc.).\n",
    "    \n",
    "    PROBLEMA: cv2.imread() falla en Windows con rutas como \"C:/A√±o2024/Mar√≠a.tif\"\n",
    "    SOLUCI√ìN: Leer archivo como bytes ‚Üí decodificar con OpenCV\n",
    "    \n",
    "    Args:\n",
    "        path (str): Ruta completa de la imagen\n",
    "        flag (int): cv2.IMREAD_COLOR (RGB) o cv2.IMREAD_GRAYSCALE\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Imagen cargada o None si hay error\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> img = cv2_imread_unicode(\"data/Paciente_Jos√©_001.tif\")\n",
    "        >>> print(img.shape)  # (256, 256, 3)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Leer archivo como array de bytes\n",
    "        stream = np.fromfile(path, dtype=np.uint8)\n",
    "        # Decodificar bytes ‚Üí imagen OpenCV\n",
    "        img = cv2.imdecode(stream, flag)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error leyendo {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def limpiar_directorio_resultados(path):\n",
    "    \"\"\"\n",
    "    Elimina y recrea la estructura de carpetas para guardar resultados.\n",
    "    \n",
    "    Estructura creada:\n",
    "    results/\n",
    "    ‚îú‚îÄ‚îÄ TP/          # True Positives (tumores correctamente detectados)\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ Dice_00_10/  # Calidad baja (0-10% overlap)\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ Dice_10_20/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "    ‚îú‚îÄ‚îÄ TN/          # True Negatives (sanos correctos)\n",
    "    ‚îú‚îÄ‚îÄ FP/          # False Positives (falsas alarmas)\n",
    "    ‚îî‚îÄ‚îÄ FN/          # False Negatives (tumores perdidos)\n",
    "    \n",
    "    Args:\n",
    "        path (str): Ruta base del directorio de resultados\n",
    "        \n",
    "    Uso:\n",
    "        >>> limpiar_directorio_resultados(\"./results\")\n",
    "    \"\"\"\n",
    "    # Si existe, borrar TODO (limpieza de ejecuciones previas)\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    \n",
    "    # Crear categor√≠as principales\n",
    "    categorias = [\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "    for cat in categorias:\n",
    "        os.makedirs(os.path.join(path, cat), exist_ok=True)\n",
    "    \n",
    "    # Subcarpetas TP por calidad se crean din√°micamente durante inferencia\n",
    "    print(f\"‚úÖ Directorio de resultados preparado: {path}\")\n",
    "\n",
    "def log_experiment_to_md(params, metrics, timings, cv_full, feat_imps, filename=\"experiment_history.md\"):\n",
    "    \"\"\"Guarda los resultados del experimento en un archivo Markdown persistente.\"\"\"\n",
    "    path = os.path.join(PROJECT_ROOT, filename)\n",
    "    mode = 'a' if os.path.exists(path) else 'w'\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    with open(path, mode, encoding='utf-8') as f:\n",
    "        if mode == 'w':\n",
    "            f.write(\"# Historial de Experimentos - Tumor Tracer AI\\n\\n\")\n",
    "        \n",
    "        f.write(f\"## üß™ Prueba: {timestamp}\\n\")\n",
    "        f.write(f\"### 1. Configuraci√≥n del Experimento\\n\")\n",
    "        f.write(f\"- **Dataset:** {params['n_images']} im√°genes (Train: {params['n_train']}, Test: {params['n_test']})\\n\")\n",
    "        f.write(f\"- **Random Forest:** `Estimators={params['rf_est']}`, `Depth={params['rf_depth']}`, `ClassWeight={params['rf_weight']}`\\n\")\n",
    "        f.write(f\"- **Tiempos:** Extrac={timings['extraction']:.1f}s | CV={timings['cv']:.1f}s | Train={timings['train']:.1f}s | Inf={timings['inference']:.1f}s | **Total={timings['total']:.1f}s**\\n\")\n",
    "        \n",
    "        f.write(f\"\\n### 2. Validaci√≥n Cruzada (K={CV_FOLDS}) - Estabilidad\\n\")\n",
    "        f.write(f\"| Fold | F1-Score | Precision | Recall |\\n\")\n",
    "        f.write(f\"|------|----------|-----------|--------|\\n\")\n",
    "        for i in range(CV_FOLDS):\n",
    "            f.write(f\"| {i+1} | {cv_full['test_f1'][i]:.4f} | {cv_full['test_precision'][i]:.4f} | {cv_full['test_recall'][i]:.4f} |\\n\")\n",
    "        \n",
    "        f.write(f\"| **Promedio** | **{metrics['cv_f1_mean']:.4f}** ¬± {metrics['cv_f1_std']*2:.4f} | {metrics['cv_prec_mean']:.4f} | {metrics['cv_rec_mean']:.4f} |\\n\")\n",
    "        \n",
    "        f.write(f\"\\n### 3. Importancia de Caracter√≠sticas (Top Influencias)\\n\")\n",
    "        f.write(f\"| Ranking | Caracter√≠stica | Importancia | Descripci√≥n |\\n\")\n",
    "        f.write(f\"|:-------:|----------------|-------------|-------------|\\n\")\n",
    "        \n",
    "        # Diccionario de descripciones breves\n",
    "        desc_map = {\n",
    "            \"Green_Excess\": \"√çndice de 'Verdosidad' (G - (R+B)/2)\",\n",
    "            \"Green_Texture\": \"Interacci√≥n Verde * Textura\",\n",
    "            \"Spatial_Radial\": \"Distancia al centro del cerebro\",\n",
    "            \"A\": \"Canal A (LAB) - Rojo/Verde\",\n",
    "            \"B_lab\": \"Canal B (LAB) - Azul/Amarillo\",\n",
    "            \"Texture_LocalStd\": \"Complejidad/Rugosidad local\",\n",
    "            \"Symmetry\": \"Diferencia entre hemisferios\"\n",
    "        }\n",
    "        \n",
    "        for i, (name, imp) in enumerate(feat_imps):\n",
    "            desc = desc_map.get(name, \"-\")\n",
    "            bold = \"**\" if i < 3 else \"\"\n",
    "            f.write(f\"| {i+1} | {bold}{name}{bold} | {imp:.4f} | {desc} |\\n\")\n",
    "            \n",
    "        f.write(f\"\\n### 4. Resultados Finales (Test Set - {params['n_test']} im√°genes)\\n\")\n",
    "        f.write(f\"#### üìä Clasificaci√≥n de Im√°genes\\n\")\n",
    "        f.write(f\"- ‚úÖ **TP (Detectados):** {metrics['TP']} im√°genes - *El modelo encontr√≥ el tumor correctamente.*\\n\")\n",
    "        f.write(f\"- ‚úÖ **TN (Sanos):** {metrics['TN']} im√°genes - *El modelo confirm√≥ que estaba sano.*\\n\")\n",
    "        f.write(f\"- ‚ùå **FP (Falsas Alarmas):** {metrics['FP']} im√°genes - *El modelo vio tumor donde no hab√≠a.*\\n\")\n",
    "        f.write(f\"- ‚ùå **FN (Perdidos):** {metrics['FN']} im√°genes - *El modelo NO vio el tumor existente.*\\n\")\n",
    "        \n",
    "        f.write(f\"\\n#### üéØ Precisi√≥n Quir√∫rgica (P√≠xel a P√≠xel)\\n\")\n",
    "        f.write(f\"- **Sensibilidad (Recall):** `{metrics['Recall']:.2%}`\\n\")\n",
    "        f.write(f\"  > De todo el tejido tumoral real, el modelo detect√≥ este porcentaje.\\n\")\n",
    "        f.write(f\"- **Confianza (Precision):** `{metrics['Precision']:.2%}`\\n\")\n",
    "        f.write(f\"  > De todo lo que el modelo marc√≥ en rojo, este porcentaje era realmente tumor.\\n\")\n",
    "        f.write(f\"- **Calidad de Segmentaci√≥n (Dice):** `{metrics['Dice']:.2%}`\\n\")\n",
    "        f.write(f\"- **Limpieza de Ruido:** Se eliminaron **{metrics['NoiseReduced']:,}** p√≠xeles de falsas alarmas durante el post-proceso.\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\\n\")\n",
    "    \n",
    "    print(f\"\\n[HISTORIAL] Resultados detallados guardados en: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Algoritmos de Preprocesamiento\n",
    "\n",
    "Antes de extraer caracter√≠sticas, normalizamos las im√°genes para reducir la variabilidad entre pacientes y esc√°neres.\n",
    "\n",
    "### 1. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "Mejora el contraste local para resaltar bordes sutiles del tumor.\n",
    "*   **T√©cnica**: Convertimos la imagen al espacio de color **LAB**. Aplicamos CLAHE solo al canal **L (Luminosidad)** y recombinamos.\n",
    "*   **Por qu√©**: Esto mejora el contraste sin distorsionar la informaci√≥n de color (canales A y B), crucial para detectar la hiperintensidad del glioma.\n",
    "\n",
    "### 2. Alineaci√≥n Geom√©trica con PCA (Principal Component Analysis)\n",
    "Los pacientes pueden tener la cabeza inclinada en el esc√°ner. Esto confunde al modelo espacialmente.\n",
    "*   **Algoritmo**:\n",
    "    1.  Binarizamos la imagen para obtener la \"nube de puntos\" del cerebro.\n",
    "    2.  Calculamos los **vectores propios (eigenvectors)** de esta nube.\n",
    "    3.  El vector propio principal indica la orientaci√≥n del eje mayor del cerebro.\n",
    "    4.  Calculamos la matriz de rotaci√≥n para alinear este eje verticalmente (90¬∞).\n",
    "*   **Correcci√≥n de Orientaci√≥n**: Usamos una heur√≠stica de centro de masa para detectar si el cerebro qued√≥ \"cabeza abajo\" y lo rotamos 180¬∞ si es necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. FUNCIONES DE PREPROCESAMIENTO\n",
    "# ==========================================\n",
    "def apply_clahe(img):\n",
    "    \"\"\"Mejora de contraste adaptativa (CLAHE) en canal L (LAB).\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l_clahe, a, b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def apply_denoise(img):\n",
    "    \"\"\"Filtro de Mediana para eliminar ruido 'sal y pimienta'.\"\"\"\n",
    "    return cv2.medianBlur(img, 3)\n",
    "\n",
    "def align_brain(img, mask=None):\n",
    "    \"\"\"\n",
    "    Alineaci√≥n geom√©trica basada en PCA.\n",
    "    Rota el cerebro para que el eje mayor sea vertical.\n",
    "    Corrige orientaci√≥n invertida usando heur√≠stica de masa.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    puntos = np.column_stack(np.where(thresh > 0)) # (y, x)\n",
    "    \n",
    "    if len(puntos) == 0:\n",
    "        return (img, mask) if mask is not None else img\n",
    "\n",
    "    # PCA Compute\n",
    "    mean, eigenvectors, _ = cv2.PCACompute2(puntos.astype(np.float32), mean=None)\n",
    "    center_img = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "    center_brain = (mean[0, 1], mean[0, 0])\n",
    "    \n",
    "    # √Ångulo y Rotaci√≥n Base\n",
    "    angle = np.arctan2(eigenvectors[0, 1], eigenvectors[0, 0])\n",
    "    rotation_angle = np.degrees(angle)\n",
    "    \n",
    "    # Forzar verticalidad\n",
    "    if abs(rotation_angle) < 45: \n",
    "        rotation_angle += 90\n",
    "        \n",
    "    M = cv2.getRotationMatrix2D(center_brain, rotation_angle, 1.0)\n",
    "    # Ajuste de traslaci√≥n para centrar\n",
    "    M[0, 2] += center_img[0] - center_brain[0]\n",
    "    M[1, 2] += center_img[1] - center_brain[1]\n",
    "    \n",
    "    # Verificaci√≥n de Orientaci√≥n (Arriba vs Abajo)\n",
    "    h, w = img.shape[:2]\n",
    "    img_temp = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    \n",
    "    gray_aligned = cv2.cvtColor(img_temp, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh_a = cv2.threshold(gray_aligned, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Heur√≠stica: Si la mitad inferior tiene mucha m√°s masa, est√° invertido\n",
    "    if np.sum(thresh_a[h//2:, :]) > np.sum(thresh_a[:h//2, :]) * 1.1:\n",
    "        rotation_angle += 180\n",
    "        M = cv2.getRotationMatrix2D(center_brain, rotation_angle, 1.0)\n",
    "        M[0, 2] += center_img[0] - center_brain[0]\n",
    "        M[1, 2] += center_img[1] - center_brain[1]\n",
    "\n",
    "    # Transformaci√≥n Final\n",
    "    img_aligned = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC)\n",
    "    if mask is not None:\n",
    "        mask_aligned = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "        return img_aligned, mask_aligned\n",
    "        \n",
    "    return img_aligned\n",
    "\n",
    "def eliminar_cerebelo_y_ruido(img_input, pred_binaria):\n",
    "    \"\"\"\n",
    "    Limpieza post-predicci√≥n (Morphology + Size Filter).\n",
    "    Nota: Se elimin√≥ el recorte fijo del 40%; el modelo ahora infiere la ubicaci√≥n.\n",
    "    \"\"\"\n",
    "    # 1. M√°scara del cerebro (ROI)\n",
    "    if len(img_input.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_input, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img_input\n",
    "        \n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    brain_mask = np.zeros_like(pred_binaria)\n",
    "    if len(contours) > 0:\n",
    "        cv2.drawContours(brain_mask, [max(contours, key=cv2.contourArea)], -1, 1, -1)\n",
    "        brain_mask = cv2.erode(brain_mask, np.ones((5,5), np.uint8), iterations=2)\n",
    "\n",
    "    # 2. Aplicar ROI\n",
    "    cleaned = cv2.bitwise_and(pred_binaria, pred_binaria, mask=brain_mask)\n",
    "\n",
    "    # 3. Filtrar manchas peque√±as (<50 px)\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(cleaned.astype(np.uint8))\n",
    "    output = np.zeros_like(cleaned)\n",
    "    for i in range(1, num):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= 50:\n",
    "            output[labels == i] = 1\n",
    "\n",
    "    # 4. Suavizado Morfol√≥gico\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    output = cv2.morphologyEx(output.astype(np.uint8), cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    return cv2.morphologyEx(output, cv2.MORPH_CLOSE, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Ingenier√≠a de Caracter√≠sticas (Feature Engineering)\n",
    "\n",
    "Transformamos cada p√≠xel en un vector de **21 dimensiones** que describe su contexto local.\n",
    "\n",
    "| Grupo | Caracter√≠stica | Descripci√≥n Matem√°tica / L√≥gica |\n",
    "| :--- | :--- | :--- |\n",
    "| **Color** | `R, G, B` | Intensidad cruda de los canales. |\n",
    "| **Color** | `Green_Excess` | $$G - \\frac{R + B}{2}$$ <br> *Detecta desviaciones del espectro de grises. √ötil para diferenciar tejido tumoral (a veces verdoso en FLAIR falso color) de artefactos.* |\n",
    "| **Color** | `H, S, V` | Matiz, Saturaci√≥n y Valor. Separa la informaci√≥n crom√°tica de la intensidad. |\n",
    "| **Color** | `L, A, B` | Espacio perceptual. El canal `L` es robusto a cambios de iluminaci√≥n. |\n",
    "| **Textura** | `Canny` | Detector de bordes binario. Marca fronteras n√≠tidas. |\n",
    "| **Textura** | `Sobel_Mag` | $$\\sqrt{Sobel_X^2 + Sobel_Y^2}$$ <br> *Magnitud del gradiente. Detecta cambios suaves de intensidad.* |\n",
    "| **Textura** | `LocalStd` | Desviaci√≥n est√°ndar en una ventana de 5x5. Mide la \"rugosidad\" o entrop√≠a local. |\n",
    "| **Interacci√≥n** | `Green_Texture` | `Green_Excess` $\\times$ `LocalStd`. <br> *Caracter√≠stica sint√©tica para diferenciar ruido verde (liso) de tumor (rugoso).* |\n",
    "| **Espacial** | `Radial` | Distancia euclidiana al centro de la imagen. Ayuda a descartar falsos positivos en el cr√°neo exterior. |\n",
    "| **Simetr√≠a** | `Symmetry` | `|Pixel(x,y) - Pixel(-x,y)|`. <br> *Diferencia absoluta con el hemisferio opuesto. Los tumores rompen la simetr√≠a natural del cerebro.* |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. INGENIER√çA DE CARACTER√çSTICAS\n",
    "# ==========================================\n",
    "def get_symmetry_feature(img):\n",
    "    \"\"\"Mapa de diferencia absoluto entre hemisferios (asume alineaci√≥n vertical).\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.absdiff(gray, cv2.flip(gray, 1))\n",
    "\n",
    "def extract_features(img):\n",
    "    \"\"\"\n",
    "    Genera un vector de caracter√≠sticas para cada p√≠xel.\n",
    "    Features: RGB, HSV, LAB, Bordes, Textura Local, Espaciales, Simetr√≠a, Interacci√≥n Verde.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    # --- Color ---\n",
    "    df['R'] = img[:, :, 2].reshape(-1)\n",
    "    df['G'] = img[:, :, 1].reshape(-1)\n",
    "    df['B'] = img[:, :, 0].reshape(-1)\n",
    "    \n",
    "    # Feature cr√≠tica: Green Excess (G - avg(R,B))\n",
    "    # Discrimina 'verde artefacto' de 'verde tejido'\n",
    "    df['Green_Excess'] = df['G'].astype(np.float32) - (df['R'].astype(np.float32) + df['B'].astype(np.float32)) / 2.0\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    df['H'] = img_hsv[:, :, 0].reshape(-1)\n",
    "    df['S'] = img_hsv[:, :, 1].reshape(-1)\n",
    "    df['V'] = img_hsv[:, :, 2].reshape(-1)\n",
    "\n",
    "    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    df['L'] = img_lab[:, :, 0].reshape(-1)\n",
    "    df['A'] = img_lab[:, :, 1].reshape(-1)\n",
    "    df['B_lab'] = img_lab[:, :, 2].reshape(-1)\n",
    "\n",
    "    # --- Textura ---\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    df['Canny'] = cv2.Canny(img_gray, 100, 200).reshape(-1)\n",
    "    df['Gaussian'] = nd.gaussian_filter(img_gray, sigma=3).reshape(-1)\n",
    "    \n",
    "    sobel_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    df['Sobel_Mag'] = np.sqrt(sobel_x**2 + sobel_y**2).reshape(-1)\n",
    "\n",
    "    # Desviaci√≥n Est√°ndar Local (Proxy de Entrop√≠a/Complejidad)\n",
    "    img_f = img_gray.astype(np.float32)\n",
    "    mu = cv2.blur(img_f, (5, 5))\n",
    "    mu2 = cv2.blur(img_f**2, (5, 5))\n",
    "    sigma = np.sqrt(np.maximum(mu2 - mu**2, 0))\n",
    "    df['Texture_LocalStd'] = sigma.reshape(-1)\n",
    "\n",
    "    # --- Interacci√≥n ---\n",
    "    # Green * Texture: Ayuda a diferenciar ruido verde (liso) de tumor verde (rugoso)\n",
    "    df['Green_Texture'] = df['Green_Excess'] * df['Texture_LocalStd']\n",
    "\n",
    "    # --- Espaciales ---\n",
    "    y, x = np.mgrid[0:h, 0:w]\n",
    "    df['Spatial_Y'] = (y / h).astype(np.float32).reshape(-1)\n",
    "    df['Spatial_X'] = (x / w).astype(np.float32).reshape(-1)\n",
    "    df['Spatial_Radial'] = np.sqrt((df['Spatial_Y'] - 0.5)**2 + (df['Spatial_X'] - 0.5)**2)\n",
    "\n",
    "    # --- Simetr√≠a ---\n",
    "    df['Symmetry'] = get_symmetry_feature(img).reshape(-1)\n",
    "\n",
    "    return df, (h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìè Definici√≥n de M√©tricas\n",
    "\n",
    "Evaluamos el rendimiento p√≠xel a p√≠xel utilizando m√©tricas est√°ndar en segmentaci√≥n m√©dica.\n",
    "\n",
    "*   **TP (True Positive):** P√≠xel de tumor correctamente identificado como tumor.\n",
    "*   **FP (False Positive):** Tejido sano incorrectamente marcado como tumor (Falsa Alarma).\n",
    "*   **FN (False Negative):** Tumor real que el modelo no detect√≥ (Error Cr√≠tico).\n",
    "\n",
    "### F√≥rmulas Clave\n",
    "\n",
    "1.  **Sensibilidad (Recall):** Capacidad de encontrar todo el tumor.\n",
    "    $$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "2.  **Precisi√≥n (Precision):** Fiabilidad de las predicciones positivas.\n",
    "    $$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "3.  **Dice Score (F1-Score):# üìè Definici√≥n de M√©tricas\n",
    "\n",
    "Evaluamos el rendimiento p√≠xel a p√≠xel utilizando m√©tricas est√°ndar en segmentaci√≥n m√©dica.\n",
    "\n",
    "*   **TP (True Positive):** P√≠xel de tumor correctamente identificado como tumor.\n",
    "*   **FP (False Positive):** Tejido sano incorrectamente marcado como tumor (Falsa Alarma).\n",
    "*   **FN (False Negative):** Tumor real que el modelo no detect√≥ (Error Cr√≠tico).\n",
    "\n",
    "### F√≥rmulas Clave\n",
    "\n",
    "1.  **Sensibilidad (Recall):** Capacidad de encontrar todo el tumor.\n",
    "    $$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "2.  **Precisi√≥n (Precision):** Fiabilidad de las predicciones positivas.\n",
    "    $$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "3.  **Dice Score (F1-Score):** M√©trica arm√≥nica que balancea precisi√≥n y recall. Es el est√°ndar para medir solapamiento en segmentaci√≥n. $$Dice = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. METRICAS Y EVALUACI√ìN\n",
    "# ==========================================\n",
    "def calcular_metricas(y_true, y_pred):\n",
    "    \"\"\"Calcula m√©tricas a nivel de p√≠xel.\"\"\"\n",
    "    true_flat = y_true.reshape(-1)\n",
    "    pred_flat = y_pred.reshape(-1)\n",
    "    \n",
    "    tp = np.sum((true_flat == 1) & (pred_flat == 1))\n",
    "    fp = np.sum((true_flat == 0) & (pred_flat == 1))\n",
    "    fn = np.sum((true_flat == 1) & (pred_flat == 0))\n",
    "    tn = np.sum((true_flat == 0) & (pred_flat == 0))\n",
    "    \n",
    "    total_pos = tp + fn\n",
    "    total_det = tp + fp\n",
    "    \n",
    "    recall = tp / total_pos if total_pos > 0 else 0.0\n",
    "    precision = tp / total_det if total_det > 0 else 0.0\n",
    "    iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0\n",
    "    dice = 2*tp / (2*tp + fp + fn) if (2*tp + fp + fn) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"TP\": tp, \"FP\": fp, \"FN\": fn, \"TN\": tn,\n",
    "        \"Recall\": recall, \"Precision\": precision, \"IoU\": iou, \"Dice\": dice\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIANDO PIPELINE DE DETECCI√ìN DE TUMORES ===\n",
      "\n",
      "[1] Buscando Dataset...\n",
      "    -> Encontrado: c:\\UAB\\3¬∫ 1¬∫\\APC\\Tumor-Tracer\\data\\dataset_plano (3929 m√°scaras)\n",
      "    -> Seleccionadas 500 im√°genes para el proceso.\n",
      "    -> Train: 400 | Test: 100\n",
      "\n",
      "[2] Extracci√≥n de Caracter√≠sticas (Train)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:14<00:00, 28.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -> Tiempo Extracci√≥n: 14.3s\n",
      "    -> Dataset Final: 1,616,772 p√≠xeles.\n",
      "    -> Distribuci√≥n: Tumor=274,693, Fondo=1,342,079\n",
      "\n",
      "[3] Validaci√≥n Cruzada (K-Fold=7)...\n",
      "    -> Resultados por Fold:\n",
      "       Fold  F1         Precision  Recall    \n",
      "       -----------------------------------\n",
      "       1     0.8937     0.9087     0.8792    \n",
      "       2     0.8967     0.9147     0.8794    \n",
      "       3     0.8864     0.9099     0.8640    \n",
      "       4     0.8908     0.9014     0.8805    \n",
      "       5     0.8986     0.9048     0.8926    \n",
      "       6     0.8948     0.9109     0.8792    \n",
      "       7     0.8953     0.9091     0.8820    \n",
      "       -----------------------------------\n",
      "    -> PROMEDIOS:\n",
      "       F1-Score  : 0.8938 (+/- 0.0075)\n",
      "       Precision : 0.9085\n",
      "       Recall    : 0.8796\n",
      "    -> Estado: ‚úÖ ESTABLE\n",
      "\n",
      "[4] Entrenando Modelo Final...\n",
      "\n",
      "    -> IMPORTANCIA DE CARACTER√çSTICAS (Todas):\n",
      "       Ranking  Feature              Importancia\n",
      "       ----------------------------------------\n",
      "       1        A                    : 0.1431\n",
      "       2        Green_Excess         : 0.1391\n",
      "       3        Spatial_Radial       : 0.1015\n",
      "       4        Green_Texture        : 0.0981\n",
      "       5        B_lab                : 0.0655\n",
      "       6        Gaussian             : 0.0543\n",
      "       7        G                    : 0.0528\n",
      "       8        Spatial_X            : 0.0457\n",
      "       9        L                    : 0.0381\n",
      "       10       Spatial_Y            : 0.0364\n",
      "       11       H                    : 0.0344\n",
      "       12       R                    : 0.0341\n",
      "       13       B                    : 0.0335\n",
      "       14       S                    : 0.0333\n",
      "       15       Texture_LocalStd     : 0.0302\n",
      "       16       V                    : 0.0240\n",
      "       17       Symmetry             : 0.0182\n",
      "       18       Sobel_Mag            : 0.0165\n",
      "       19       Canny                : 0.0011\n",
      "\n",
      "[5] Evaluando en Test Set (100 im√°genes)...\n",
      "Directorio de resultados preparado: c:\\UAB\\3¬∫ 1¬∫\\APC\\Tumor-Tracer\\results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencia: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:54<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REPORTE FINAL DE EJECUCI√ìN\n",
      "============================================================\n",
      "1. CLASIFICACI√ìN DE IM√ÅGENES\n",
      "   Total: 100\n",
      "   ‚úÖ TP:  32 (32.00%)\n",
      "   ‚úÖ TN:  38 (38.00%)\n",
      "   ‚ùå FP:  29 (29.00%)\n",
      "   ‚ùå FN:   1 ( 1.00%)\n",
      "\n",
      "2. CALIDAD DE SEGMENTACI√ìN (Casos TP)\n",
      "   Dice Promedio: 69.33%\n",
      "\n",
      "3. PRECISI√ìN QUIR√öRGICA (P√≠xeles)\n",
      "   Sensibilidad (Recall): 74.25%\n",
      "   Confianza (Precision): 58.51%\n",
      "   Ruido Eliminado:       58,627 p√≠xeles\n",
      "\n",
      "4. TIEMPOS DE EJECUCI√ìN\n",
      "   Extracci√≥n (Train): 14.27 s\n",
      "   Cross-Validation:   22.62 s\n",
      "   Entrenamiento:      111.89 s\n",
      "   Inferencia (Test):  54.84 s\n",
      "   TOTAL SCRIPT:       204.68 s\n",
      "\n",
      "[HISTORIAL] Resultados detallados guardados en: experiment_history.md\n",
      "\n",
      "[FIN] Resultados guardados en 'results/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 6. PIPELINE PRINCIPAL (MAIN)\n",
    "# ==========================================\n",
    "t_start_total = time.time()\n",
    "timings = {}\n",
    "\n",
    "print(\"\\n=== INICIANDO PIPELINE DE DETECCI√ìN DE TUMORES ===\")\n",
    "\n",
    "# --- 1. Buscar Datos ---\n",
    "print(\"\\n[1] Buscando Dataset...\")\n",
    "search_paths = [\n",
    "    os.path.join(PROJECT_ROOT, \"data\", \"dataset_plano\"),\n",
    "    os.path.join(PROJECT_ROOT, \"data\", \"kaggle_3m\")\n",
    "]\n",
    "\n",
    "files_found = []\n",
    "for p in search_paths:\n",
    "    if os.path.exists(p):\n",
    "        curr = glob.glob(os.path.join(p, '**', '*_mask.tif'), recursive=True)\n",
    "        if curr:\n",
    "            files_found = curr\n",
    "            print(f\"    -> Encontrado: {p} ({len(curr)} m√°scaras)\")\n",
    "            break\n",
    "\n",
    "if not files_found:\n",
    "    print(\"[ERROR] No se encontraron datos. Revise las rutas.\")\n",
    "else:\n",
    "    # Preparar pares validos\n",
    "    valid_pairs = []\n",
    "    for mask_p in files_found:\n",
    "        img_p = mask_p.replace('_mask.tif', '.tif')\n",
    "        if os.path.exists(img_p):\n",
    "            valid_pairs.append((img_p, mask_p))\n",
    "\n",
    "    # Selecci√≥n Aleatoria\n",
    "    sample_size = min(NUM_IMAGES, len(valid_pairs))\n",
    "    random.seed(RANDOM_STATE)\n",
    "    selected = random.sample(valid_pairs, sample_size)\n",
    "    print(f\"    -> Seleccionadas {len(selected)} im√°genes para el proceso.\")\n",
    "\n",
    "    # Split Train/Test\n",
    "    train_pairs, test_pairs = train_test_split(selected, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    print(f\"    -> Train: {len(train_pairs)} | Test: {len(test_pairs)}\")\n",
    "\n",
    "    # --- 2. Extracci√≥n de Features (Entrenamiento) ---\n",
    "    print(f\"\\n[2] Extracci√≥n de Caracter√≠sticas (Train)...\")\n",
    "    t_start_extract = time.time()\n",
    "    X_train_list, Y_train_list = [], []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for img_p, mask_p in tqdm(train_pairs, desc=\"Procesando Train\"):\n",
    "        img = cv2_imread_unicode(img_p)\n",
    "        mask = cv2_imread_unicode(mask_p, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None or mask is None: continue\n",
    "\n",
    "        # Pipeline Preproceso\n",
    "        img = apply_clahe(img)\n",
    "        img = apply_denoise(img)\n",
    "        img, mask = align_brain(img, mask)\n",
    "\n",
    "        mask = (mask // 255).reshape(-1)\n",
    "        features, _ = extract_features(img)\n",
    "        features = features.astype(np.float32)\n",
    "\n",
    "        # Subsampling estrategico\n",
    "        idx_tumor = np.where(mask == 1)[0]\n",
    "        idx_backg = np.where(mask == 0)[0]\n",
    "        \n",
    "        counts_t = len(idx_tumor)\n",
    "        counts_b = len(idx_backg)\n",
    "        \n",
    "        sample_indices = []\n",
    "        if counts_t > 0:\n",
    "            # Tomar todo el tumor y 3x de fondo\n",
    "            needed_b = min(counts_b, counts_t * SUBSAMPLE_RATIO)\n",
    "            if needed_b > 0:\n",
    "                sample_indices = np.concatenate([\n",
    "                    idx_tumor, \n",
    "                    np.random.choice(idx_backg, needed_b, replace=False)\n",
    "                ])\n",
    "            else:\n",
    "                sample_indices = idx_tumor\n",
    "        else:\n",
    "            # Imagen sana: tomar peque√±a muestra representativa\n",
    "            sample_indices = np.random.choice(idx_backg, min(counts_b, 2000), replace=False)\n",
    "\n",
    "        X_train_list.append(features.iloc[sample_indices])\n",
    "        Y_train_list.append(mask[sample_indices])\n",
    "\n",
    "    time_extract = time.time() - t_start_extract\n",
    "    timings['extraction'] = time_extract\n",
    "    print(f\"    -> Tiempo Extracci√≥n: {time_extract:.1f}s\")\n",
    "    \n",
    "    # Consolidar\n",
    "    X_train = pd.concat(X_train_list)\n",
    "    Y_train = np.concatenate(Y_train_list)\n",
    "    del X_train_list, Y_train_list\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"    -> Dataset Final: {len(X_train):,} p√≠xeles.\")\n",
    "    print(f\"    -> Distribuci√≥n: Tumor={np.sum(Y_train==1):,}, Fondo={np.sum(Y_train==0):,}\")\n",
    "\n",
    "    # --- 3. Validaci√≥n Cruzada ---\n",
    "    print(f\"\\n[3] Validaci√≥n Cruzada (K-Fold={CV_FOLDS})...\")\n",
    "    t_start_cv = time.time()\n",
    "    # Muestra reducida para CV rapido\n",
    "    cv_idx = np.random.choice(len(Y_train), min(100000, len(Y_train)), replace=False)\n",
    "    \n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=RF_ESTIMATORS,\n",
    "        max_depth=RF_MAX_DEPTH,\n",
    "        class_weight=RF_CLASS_WEIGHT,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    \n",
    "    kfold = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    # Usamos cross_validate para obtener m√∫ltiples m√©tricas\n",
    "    scoring_metrics = ['f1', 'precision', 'recall']\n",
    "    scores = cross_validate(rf_model, X_train.iloc[cv_idx], Y_train[cv_idx], cv=kfold, scoring=scoring_metrics, n_jobs=1)\n",
    "    \n",
    "    print(f\"    -> Resultados por Fold:\")\n",
    "    print(f\"       {'Fold':<5} {'F1':<10} {'Precision':<10} {'Recall':<10}\")\n",
    "    print(f\"       {'-'*35}\")\n",
    "    \n",
    "    for i in range(CV_FOLDS):\n",
    "        f1 = scores['test_f1'][i]\n",
    "        prec = scores['test_precision'][i]\n",
    "        rec = scores['test_recall'][i]\n",
    "        print(f\"       {i+1:<5d} {f1:<10.4f} {prec:<10.4f} {rec:<10.4f}\")\n",
    "        \n",
    "    print(f\"       {'-'*35}\")\n",
    "    print(f\"    -> PROMEDIOS:\")\n",
    "    print(f\"       F1-Score  : {scores['test_f1'].mean():.4f} (+/- {scores['test_f1'].std()*2:.4f})\")\n",
    "    print(f\"       Precision : {scores['test_precision'].mean():.4f}\")\n",
    "    print(f\"       Recall    : {scores['test_recall'].mean():.4f}\")\n",
    "    \n",
    "    stability = scores['test_f1'].std() < 0.05\n",
    "    print(f\"    -> Estado: {'‚úÖ ESTABLE' if stability else '‚ö†Ô∏è INESTABLE'}\")\n",
    "\n",
    "    time_cv = time.time() - t_start_cv\n",
    "    timings['cv'] = time_cv\n",
    "\n",
    "    # --- 4. Entrenamiento Final ---\n",
    "    print(f\"\\n[4] Entrenando Modelo Final...\")\n",
    "    t_start_train = time.time()\n",
    "    rf_model.fit(X_train, Y_train)\n",
    "    time_train = time.time() - t_start_train\n",
    "    timings['train'] = time_train\n",
    "\n",
    "    \n",
    "    # Importancias\n",
    "    imps = rf_model.feature_importances_\n",
    "    feat_names = X_train.columns\n",
    "    sorted_idx = np.argsort(imps)[::-1]\n",
    "    \n",
    "    # Guardar lista de features para el reporte\n",
    "    feature_importance_list = []\n",
    "    \n",
    "    print(\"\\n    -> IMPORTANCIA DE CARACTER√çSTICAS (Todas):\")\n",
    "    print(f\"       {'Ranking':<8} {'Feature':<20} {'Importancia':<10}\")\n",
    "    print(f\"       {'-'*40}\")\n",
    "    for i in range(len(feat_names)):\n",
    "        idx = sorted_idx[i]\n",
    "        name = feat_names[idx]\n",
    "        val = imps[idx]\n",
    "        feature_importance_list.append((name, val))\n",
    "        print(f\"       {i+1:<8d} {name:<20s} : {val:.4f}\")\n",
    "\n",
    "    # --- 5. Inferencia y Evaluaci√≥n (Test) ---\n",
    "    print(f\"\\n[5] Evaluando en Test Set ({len(test_pairs)} im√°genes)...\")\n",
    "    results_dir = os.path.join(PROJECT_ROOT, \"results\")\n",
    "    limpiar_directorio_resultados(results_dir)\n",
    "    \n",
    "    global_metrics = {\"TP\":0, \"FP\":0, \"FN\":0, \"TN\":0}\n",
    "    img_counts = {\"TP\":0, \"TN\":0, \"FP\":0, \"FN\":0}\n",
    "    tp_qualities = [] # Dice scores\n",
    "\n",
    "    metrics_raw = {\"TP\":0, \"FP\":0, \"FN\":0} # Antes de limpiar\n",
    "    \n",
    "    total_cleaned_pixels = 0\n",
    "    \n",
    "    t_start_inf = time.time()\n",
    "    for img_p, mask_p in tqdm(test_pairs, desc=\"Inferencia\"):\n",
    "\n",
    "        img_orig = cv2_imread_unicode(img_p)\n",
    "        mask_orig = cv2_imread_unicode(mask_p, cv2.IMREAD_GRAYSCALE)\n",
    "        fname = os.path.basename(img_p)\n",
    "        \n",
    "        if img_orig is None: continue\n",
    "\n",
    "        # Preproceso Test\n",
    "        img = apply_clahe(img_orig)\n",
    "        img = apply_denoise(img)\n",
    "        img, mask = align_brain(img, mask_orig)\n",
    "        mask_bin = (mask // 255).astype(np.uint8)\n",
    "\n",
    "        # Prediccion\n",
    "        feat_df, (h, w) = extract_features(img)\n",
    "        pred_flat = rf_model.predict(feat_df)\n",
    "        pred_map = pred_flat.reshape(h, w).astype(np.uint8)\n",
    "        \n",
    "        # Guardar metricas RAW\n",
    "        m_raw = calcular_metricas(mask_bin, pred_map)\n",
    "        metrics_raw[\"FP\"] += m_raw[\"FP\"]\n",
    "\n",
    "        # Limpieza\n",
    "        clean_map = eliminar_cerebelo_y_ruido(img, pred_map)\n",
    "        \n",
    "        # Metricas FINALES\n",
    "        m_final = calcular_metricas(mask_bin, clean_map)\n",
    "        total_cleaned_pixels += (m_raw[\"FP\"] - m_final[\"FP\"])\n",
    "        \n",
    "        # Acumular globales\n",
    "        for k in global_metrics: global_metrics[k] += m_final[k]\n",
    "        \n",
    "        # Clasificar Imagen\n",
    "        has_tumor = np.sum(mask_bin) > 0\n",
    "        detected = np.sum(clean_map) > 0\n",
    "        cat = \"TN\"\n",
    "        if has_tumor and detected: cat = \"TP\"\n",
    "        elif has_tumor and not detected: cat = \"FN\"\n",
    "        elif not has_tumor and detected: cat = \"FP\"\n",
    "        \n",
    "        img_counts[cat] += 1\n",
    "        \n",
    "        # Guardar (Solo TP o errores FP/FN interesante guardar)\n",
    "        # Gestionar carpetas din√°micas para TP\n",
    "        save_subdir = cat\n",
    "        extra_txt = \"\"\n",
    "        \n",
    "        if cat == \"TP\":\n",
    "            dice = m_final[\"Dice\"]\n",
    "            tp_qualities.append(dice)\n",
    "            decile = min(int(dice * 10), 9) * 10\n",
    "            save_subdir = os.path.join(\"TP\", f\"Dice_{decile:02d}_{decile+10:02d}\")\n",
    "            os.makedirs(os.path.join(results_dir, save_subdir), exist_ok=True)\n",
    "            extra_txt = f\"Dice: {dice:.2%}\"\n",
    "        elif cat == \"FP\":\n",
    "            extra_txt = f\"Ruido: {m_final['FP']} px\"\n",
    "            \n",
    "        # Generar Plot (Solo guardar)\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        fig.suptitle(f\"[{cat}] {fname} | {extra_txt}\")\n",
    "        axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); axs[0].set_title(\"Input (Aligned)\")\n",
    "        axs[1].imshow(mask_bin, cmap='gray'); axs[1].set_title(\"Ground Truth\")\n",
    "        axs[2].imshow(clean_map, cmap='Reds'); axs[2].set_title(\"Predicci√≥n AI\")\n",
    "        for ax in axs: ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, save_subdir, f\"res_{fname}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    time_inf = time.time() - t_start_inf\n",
    "    timings['inference'] = time_inf\n",
    "    timings['total'] = time.time() - t_start_total\n",
    "\n",
    "    # --- 6. Reporte Final ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REPORTE FINAL DE EJECUCI√ìN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Imagenes\n",
    "    n_test = len(test_pairs)\n",
    "    print(\"1. CLASIFICACI√ìN DE IM√ÅGENES\")\n",
    "    print(f\"   Total: {n_test}\")\n",
    "    print(f\"   ‚úÖ TP: {img_counts['TP']:3d} ({img_counts['TP']/n_test:6.2%})\")\n",
    "    print(f\"   ‚úÖ TN: {img_counts['TN']:3d} ({img_counts['TN']/n_test:6.2%})\")\n",
    "    print(f\"   ‚ùå FP: {img_counts['FP']:3d} ({img_counts['FP']/n_test:6.2%})\")\n",
    "    print(f\"   ‚ùå FN: {img_counts['FN']:3d} ({img_counts['FN']/n_test:6.2%})\")\n",
    "    \n",
    "    # 2. Calidad\n",
    "    print(\"\\n2. CALIDAD DE SEGMENTACI√ìN (Casos TP)\")\n",
    "    avg_dice = np.mean(tp_qualities) if tp_qualities else 0.0\n",
    "    if tp_qualities:\n",
    "        print(f\"   Dice Promedio: {avg_dice:.2%}\")\n",
    "    else:\n",
    "        print(\"   (No hubo casos TP)\")\n",
    "\n",
    "    # 3. Pixeles\n",
    "    print(\"\\n3. PRECISI√ìN QUIR√öRGICA (P√≠xeles)\")\n",
    "    tot_p = global_metrics[\"TP\"] + global_metrics[\"FN\"]\n",
    "    tot_det = global_metrics[\"TP\"] + global_metrics[\"FP\"]\n",
    "    \n",
    "    sens = global_metrics[\"TP\"] / tot_p if tot_p > 0 else 0\n",
    "    conf = global_metrics[\"TP\"] / tot_det if tot_det > 0 else 0\n",
    "    \n",
    "    print(f\"   Sensibilidad (Recall): {sens:6.2%}\")\n",
    "    print(f\"   Confianza (Precision): {conf:6.2%}\")\n",
    "    print(f\"   Ruido Eliminado:       {total_cleaned_pixels:,} p√≠xeles\")\n",
    "    \n",
    "    # 4. Tiempos\n",
    "    print(\"\\n4. TIEMPOS DE EJECUCI√ìN\")\n",
    "    print(f\"   Extracci√≥n (Train): {timings['extraction']:.2f} s\")\n",
    "    print(f\"   Cross-Validation:   {timings['cv']:.2f} s\")\n",
    "    print(f\"   Entrenamiento:      {timings['train']:.2f} s\")\n",
    "    print(f\"   Inferencia (Test):  {timings['inference']:.2f} s\")\n",
    "    print(f\"   TOTAL SCRIPT:       {timings['total']:.2f} s\")\n",
    "\n",
    "    # --- LOG A MARKDOWN ---\n",
    "    params = {\n",
    "        'n_images': len(selected),\n",
    "        'n_train': len(train_pairs),\n",
    "        'n_test': len(test_pairs),\n",
    "        'rf_est': RF_ESTIMATORS,\n",
    "        'rf_depth': RF_MAX_DEPTH,\n",
    "        'rf_weight': str(RF_CLASS_WEIGHT)\n",
    "    }\n",
    "    \n",
    "    metrics = {\n",
    "        'TP': img_counts['TP'], 'TN': img_counts['TN'], 'FP': img_counts['FP'], 'FN': img_counts['FN'],\n",
    "        'Recall': sens, 'Precision': conf, 'Dice': avg_dice,\n",
    "        'NoiseReduced': total_cleaned_pixels,\n",
    "        'cv_f1_mean': scores['test_f1'].mean(),\n",
    "        'cv_f1_std': scores['test_f1'].std(),\n",
    "        'cv_prec_mean': scores['test_precision'].mean(),\n",
    "        'cv_rec_mean': scores['test_recall'].mean()\n",
    "    }\n",
    "    \n",
    "    log_experiment_to_md(params, metrics, timings, scores, feature_importance_list)\n",
    "    \n",
    "    print(\"\\n[FIN] Resultados guardados en 'results/'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tumor-tracer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
